{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the sigir17 data from https://sites.google.com/site/limkwanhui/datacode\n",
    "# curl 'https://doc-00-b8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/jbv2cduus8cnmhdbt7drradcako8r0ft/1550836800000/15465375115408245011/*/1TXw_HoUiyMLylcZY3VB5vsZG9jG0W1Je' > ~/SageMaker/mastering-ml-on-aws/chapter6/data-sigir17.zip\n",
    "# cd /SageMaker/mastering-ml-on-aws/chapter6/\n",
    "# unzip data-sigir17.zip\n",
    "# remove README files from all dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "\n",
    "SRC_PATH = expanduser(\"~\") + '/SageMaker/mastering-ml-on-aws/chapter6/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "\n",
    "sc = SparkContext('local', 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df = spark.read.csv(SRC_PATH + 'data-sigir17/poiList-sigir17', header=True, inferSchema=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poiID</th>\n",
       "      <th>poiName</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>rideDuration</th>\n",
       "      <th>theme</th>\n",
       "      <th>theme2</th>\n",
       "      <th>theme3</th>\n",
       "      <th>theme4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Gadget's Go Coaster</td>\n",
       "      <td>33.810259</td>\n",
       "      <td>-117.918438</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Kiddie</td>\n",
       "      <td>Roller Coaster</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Astro Orbitor</td>\n",
       "      <td>28.418532</td>\n",
       "      <td>-81.579153</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Spinning Ride</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mad Tea Party</td>\n",
       "      <td>33.813458</td>\n",
       "      <td>-117.918289</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Family</td>\n",
       "      <td>Spinning Ride</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Dumbo the Flying Elephant</td>\n",
       "      <td>33.813680</td>\n",
       "      <td>-117.918928</td>\n",
       "      <td>1.67</td>\n",
       "      <td>Family</td>\n",
       "      <td>Spinning Ride</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   poiID                    poiName        lat        long  rideDuration  \\\n",
       "0      1        Gadget's Go Coaster  33.810259 -117.918438          1.00   \n",
       "1      2              Astro Orbitor  28.418532  -81.579153          1.50   \n",
       "2      3              Mad Tea Party  33.813458 -117.918289          1.50   \n",
       "3      4  Dumbo the Flying Elephant  33.813680 -117.918928          1.67   \n",
       "\n",
       "           theme          theme2 theme3 theme4  \n",
       "0         Kiddie  Roller Coaster   None   None  \n",
       "1  Spinning Ride            None   None   None  \n",
       "2         Family   Spinning Ride   None   None  \n",
       "3         Family   Spinning Ride   None   None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_df.limit(4).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df = spark.read.csv(SRC_PATH + 'data-sigir17/userVisits-sigir17', header=True, inferSchema=True, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = visits_df.limit(1000).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nsid</th>\n",
       "      <th>takenUnix</th>\n",
       "      <th>poiID</th>\n",
       "      <th>poiTheme</th>\n",
       "      <th>poiFreq</th>\n",
       "      <th>rideDuration</th>\n",
       "      <th>seqID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5858403310</td>\n",
       "      <td>10004778@N07</td>\n",
       "      <td>1308262550</td>\n",
       "      <td>6</td>\n",
       "      <td>Ride</td>\n",
       "      <td>1665</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5857850631</td>\n",
       "      <td>10004778@N07</td>\n",
       "      <td>1308270702</td>\n",
       "      <td>26</td>\n",
       "      <td>Family</td>\n",
       "      <td>18710</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5858399220</td>\n",
       "      <td>10004778@N07</td>\n",
       "      <td>1308631356</td>\n",
       "      <td>6</td>\n",
       "      <td>Ride</td>\n",
       "      <td>1665</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8277294024</td>\n",
       "      <td>10004778@N07</td>\n",
       "      <td>1355568624</td>\n",
       "      <td>26</td>\n",
       "      <td>Family</td>\n",
       "      <td>18710</td>\n",
       "      <td>900.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9219062165</td>\n",
       "      <td>10004778@N07</td>\n",
       "      <td>1373030964</td>\n",
       "      <td>29</td>\n",
       "      <td>Water</td>\n",
       "      <td>10427</td>\n",
       "      <td>900.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id          nsid   takenUnix  poiID poiTheme  poiFreq  \\\n",
       "0  5858403310  10004778@N07  1308262550      6     Ride     1665   \n",
       "1  5857850631  10004778@N07  1308270702     26   Family    18710   \n",
       "2  5858399220  10004778@N07  1308631356      6     Ride     1665   \n",
       "3  8277294024  10004778@N07  1355568624     26   Family    18710   \n",
       "4  9219062165  10004778@N07  1373030964     29    Water    10427   \n",
       "\n",
       "   rideDuration  seqID  \n",
       "0         120.0      1  \n",
       "1         900.0      1  \n",
       "2         120.0      2  \n",
       "3         900.0      3  \n",
       "4         900.0      4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "      <th>nsid</th>\n",
       "      <th>takenUnix</th>\n",
       "      <th>poiID</th>\n",
       "      <th>poiTheme</th>\n",
       "      <th>poiFreq</th>\n",
       "      <th>rideDuration</th>\n",
       "      <th>seqID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>332091</td>\n",
       "      <td>332091</td>\n",
       "      <td>332091</td>\n",
       "      <td>332091</td>\n",
       "      <td>332091</td>\n",
       "      <td>332091</td>\n",
       "      <td>332091</td>\n",
       "      <td>332091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>8.916292302139416E9</td>\n",
       "      <td>None</td>\n",
       "      <td>1.3233824075555675E9</td>\n",
       "      <td>15.975127299445031</td>\n",
       "      <td>None</td>\n",
       "      <td>6181.338365086678</td>\n",
       "      <td>740.7857015095311</td>\n",
       "      <td>4288.19415762547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>6.226917245549271E9</td>\n",
       "      <td>None</td>\n",
       "      <td>7.424485813151878E7</td>\n",
       "      <td>8.695388902420351</td>\n",
       "      <td>None</td>\n",
       "      <td>5199.41535123871</td>\n",
       "      <td>488.5329445328169</td>\n",
       "      <td>3093.323953206581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>102530213</td>\n",
       "      <td>10000151@N02</td>\n",
       "      <td>1187918299</td>\n",
       "      <td>1</td>\n",
       "      <td>Dark</td>\n",
       "      <td>162</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>29475731115</td>\n",
       "      <td>99987318@N03</td>\n",
       "      <td>1471870895</td>\n",
       "      <td>31</td>\n",
       "      <td>Water</td>\n",
       "      <td>18710</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>11758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                   id          nsid             takenUnix  \\\n",
       "0   count               332091        332091                332091   \n",
       "1    mean  8.916292302139416E9          None  1.3233824075555675E9   \n",
       "2  stddev  6.226917245549271E9          None   7.424485813151878E7   \n",
       "3     min            102530213  10000151@N02            1187918299   \n",
       "4     max          29475731115  99987318@N03            1471870895   \n",
       "\n",
       "                poiID poiTheme            poiFreq       rideDuration  \\\n",
       "0              332091   332091             332091             332091   \n",
       "1  15.975127299445031     None  6181.338365086678  740.7857015095311   \n",
       "2   8.695388902420351     None   5199.41535123871  488.5329445328169   \n",
       "3                   1     Dark                162               60.0   \n",
       "4                  31    Water              18710             2700.0   \n",
       "\n",
       "               seqID  \n",
       "0             332091  \n",
       "1   4288.19415762547  \n",
       "2  3093.323953206581  \n",
       "3                  1  \n",
       "4              11758  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visits_df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>takenUnix</th>\n",
       "      <th>poiID</th>\n",
       "      <th>poiFreq</th>\n",
       "      <th>rideDuration</th>\n",
       "      <th>seqID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.448781e+09</td>\n",
       "      <td>1.328379e+09</td>\n",
       "      <td>20.785000</td>\n",
       "      <td>7764.625000</td>\n",
       "      <td>625.260600</td>\n",
       "      <td>50.349000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.805738e+09</td>\n",
       "      <td>6.346368e+07</td>\n",
       "      <td>8.138243</td>\n",
       "      <td>6233.964628</td>\n",
       "      <td>324.947216</td>\n",
       "      <td>20.027838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.643421e+09</td>\n",
       "      <td>1.191397e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.075781e+09</td>\n",
       "      <td>1.308877e+09</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2757.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.222417e+09</td>\n",
       "      <td>1.310770e+09</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4082.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.151750e+10</td>\n",
       "      <td>1.376198e+09</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>16366.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.777601e+10</td>\n",
       "      <td>1.466605e+09</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>18710.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     takenUnix        poiID       poiFreq  rideDuration  \\\n",
       "count  1.000000e+03  1.000000e+03  1000.000000   1000.000000   1000.000000   \n",
       "mean   8.448781e+09  1.328379e+09    20.785000   7764.625000    625.260600   \n",
       "std    4.805738e+09  6.346368e+07     8.138243   6233.964628    324.947216   \n",
       "min    1.643421e+09  1.191397e+09     1.000000    580.000000     60.000000   \n",
       "25%    6.075781e+09  1.308877e+09    15.000000   2757.000000    270.000000   \n",
       "50%    6.222417e+09  1.310770e+09    23.000000   4082.000000    600.000000   \n",
       "75%    1.151750e+10  1.376198e+09    28.000000  16366.000000    900.000000   \n",
       "max    2.777601e+10  1.466605e+09    31.000000  18710.000000   1500.000000   \n",
       "\n",
       "             seqID  \n",
       "count  1000.000000  \n",
       "mean     50.349000  \n",
       "std      20.027838  \n",
       "min       1.000000  \n",
       "25%      33.000000  \n",
       "50%      56.000000  \n",
       "75%      69.000000  \n",
       "max      73.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count             1000\n",
       "unique              36\n",
       "top       10182842@N08\n",
       "freq               365\n",
       "Name: nsid, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.nsid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df.createOrReplaceTempView('visits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df.createOrReplaceTempView('points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('select distinct poiID from visits').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-----------------+\n",
      "|summary|        nsid|              cnt|\n",
      "+-------+------------+-----------------+\n",
      "|  count|        8903|             8903|\n",
      "|   mean|        null| 4.86027181848815|\n",
      "| stddev|        null|5.965584836576787|\n",
      "|    min|10000151@N02|                1|\n",
      "|    max|99987318@N03|               31|\n",
      "+-------+------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select nsid,count(distinct poiID) as cnt from visits group by nsid').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------------------+-----------------+\n",
      "|summary|        nsid|             poiID|         count(1)|\n",
      "+-------+------------+------------------+-----------------+\n",
      "|  count|       43271|             43271|            43271|\n",
      "|   mean|        null|14.920061935245315|7.674678190936193|\n",
      "| stddev|        null| 8.437883931275111|52.93100615991835|\n",
      "|    min|10000151@N02|                 1|                1|\n",
      "|    max|99987318@N03|                31|             4128|\n",
      "+-------+------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select nsid,poiID,count(*) from visits group by nsid,poiID').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = spark.sql('select hash(nsid) as user_hash_id, poiID, count(*) as pictures_taken from visits group by 1,2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43271"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_hash_id</th>\n",
       "      <th>poiID</th>\n",
       "      <th>pictures_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1861435726</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1064654977</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-636721096</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_hash_id  poiID  pictures_taken\n",
       "0   -1861435726     19               7\n",
       "1   -1064654977     26               8\n",
       "2    -636721096     17               1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "recommender = ALS(userCol=\"user_hash_id\", itemCol=\"poiID\", ratingCol=\"pictures_taken\", coldStartStrategy=\"drop\")\n",
    "\n",
    "model = recommender.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_hash_id</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>413285690</td>\n",
       "      <td>[(25, 39.260990142822266), (18, 34.83002853393...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005782960</td>\n",
       "      <td>[(29, 6.377601146697998), (25, 6.2345833778381...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1410121870</td>\n",
       "      <td>[(25, 12.15351390838623), (29, 11.446855545043...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_hash_id                                    recommendations\n",
       "0     413285690  [(25, 39.260990142822266), (18, 34.83002853393...\n",
       "1    1005782960  [(29, 6.377601146697998), (25, 6.2345833778381...\n",
       "2    1410121870  [(25, 12.15351390838623), (29, 11.446855545043..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations.createOrReplaceTempView('recommendations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list = spark.sql('select distinct p.poiName, p.poiID from visits v join points p on (p.poiID=v.poiID) ').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_poi_name =  dict(map(lambda x: (x.poiID, x.poiName), row_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Test Track',\n",
       " 10: 'Golden Zephyr',\n",
       " 19: \"Tarzan's Treehouse\",\n",
       " 22: 'Country Bear Jamboree',\n",
       " 9: \"Pinocchio's Daring Journey\",\n",
       " 21: 'Red Car Trolley & News Boys',\n",
       " 13: 'Haunted Mansion',\n",
       " 26: 'Sleeping Beauty Castle Walkthrough',\n",
       " 8: 'The Great Movie Ride',\n",
       " 12: \"It's A Small World\",\n",
       " 20: 'Splash Mountain',\n",
       " 29: 'Pirates of the Caribbean',\n",
       " 16: 'Buzz Lightyear Astro Blasters',\n",
       " 25: \"It's A Small World\",\n",
       " 14: 'The Many Adventures of Winnie the Pooh',\n",
       " 11: \"California Screamin'\",\n",
       " 15: 'The Twilight Zone Tower of Terror',\n",
       " 3: \"Soarin'\",\n",
       " 4: 'Journey Into Imagination With Figment',\n",
       " 24: 'Jungle Cruise',\n",
       " 2: 'Astro Orbiter',\n",
       " 5: 'Silly Symphony Swings',\n",
       " 6: \"Snow White's Scary Adventures\",\n",
       " 30: 'Mark Twain Riverboat',\n",
       " 28: 'Main Street Cinema',\n",
       " 7: 'Voyage of The Little Mermaid',\n",
       " 23: 'Redwood Creek Challenge Trail',\n",
       " 18: 'Tom Sawyer Island',\n",
       " 27: 'Walt Disney World Railroad',\n",
       " 17: 'Rose & Crown Pub Musician',\n",
       " 31: 'Fantasmic!'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_poi_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.poi_names(recommendations, visited_pois)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def poi_names(recommendations, visited_pois):\n",
    "    visited_set = set([id_to_poi_name[poi] for poi in visited_pois])\n",
    "    recommended = str([(id_to_poi_name[poi], weight) for (poi,weight) in recommendations \n",
    "                       if id_to_poi_name[poi] not in visited_set])\n",
    "    return \"recommended: %s ; visited: %s \"%(recommended, visited_set)\n",
    "\n",
    "spark.udf.register(\"poi_names\", poi_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_sample = spark.sql('select user_hash_id, collect_list(poiID), poi_names(max(recommendations), collect_list(poiID)) as recommendation from recommendations r join visits v on (r.user_hash_id = hash(v.nsid)) group by 1').sample(fraction=0.1, withReplacement=False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommended: [(\"It's A Small World\", 31.352962493896484), ('Walt Disney World Railroad', 23.464025497436523), ('Pirates of the Caribbean', 21.36219596862793), ('Buzz Lightyear Astro Blasters', 17.21680450439453), ('Haunted Mansion', 15.873616218566895), ('Country Bear Jamboree', 9.63521957397461), ('Astro Orbiter', 9.164801597595215), ('The Great Movie Ride', 8.167647361755371)] ; visited: {\"California Screamin'\", 'Sleeping Beauty Castle Walkthrough', 'Voyage of The Little Mermaid', \"Tarzan's Treehouse\", 'Main Street Cinema', 'The Many Adventures of Winnie the Pooh', 'Jungle Cruise', 'Tom Sawyer Island', 'Test Track', 'The Twilight Zone Tower of Terror'} \n"
     ]
    }
   ],
   "source": [
    "print(recommendation_sample[0].recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommended: [('Splash Mountain', 0.9785523414611816), ('Sleeping Beauty Castle Walkthrough', 0.8383632302284241), (\"Pinocchio's Daring Journey\", 0.7456990480422974), ('Journey Into Imagination With Figment', 0.4501221477985382), (\"California Screamin'\", 0.44446268677711487), ('Tom Sawyer Island', 0.41949236392974854), (\"It's A Small World\", 0.40130260586738586), ('Astro Orbiter', 0.37899214029312134), ('The Twilight Zone Tower of Terror', 0.3728359639644623)] ; visited: {\"Snow White's Scary Adventures\"} \n"
     ]
    }
   ],
   "source": [
    "print(recommendation_sample[200].recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommended: [('Fantasmic!', 20.900590896606445), ('Pirates of the Caribbean', 9.25596809387207), (\"It's A Small World\", 8.825133323669434), ('Buzz Lightyear Astro Blasters', 5.474684715270996), ('Main Street Cinema', 5.1001691818237305), ('Country Bear Jamboree', 4.3145904541015625), (\"California Screamin'\", 3.717888832092285), (\"It's A Small World\", 3.6027705669403076), ('The Many Adventures of Winnie the Pooh', 3.429044246673584)] ; visited: {'Haunted Mansion', 'The Twilight Zone Tower of Terror', 'Journey Into Imagination With Figment'} \n"
     ]
    }
   ],
   "source": [
    "print(recommendation_sample[600].recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages = [\n",
    "    StringIndexer(inputCol='user_hash_id', outputCol=\"user_hash_id_index\", handleInvalid='keep'),\n",
    "    OneHotEncoder(inputCol='user_hash_id_index', outputCol='user_hash_id_encoded'),\n",
    "    StringIndexer(inputCol='poiID', outputCol='poi_id_indexed', handleInvalid='keep'),\n",
    "    OneHotEncoder(inputCol='poi_id_indexed', outputCol='poi_id_encoded'),\n",
    "    QuantileDiscretizer(numBuckets=5, inputCol='pictures_taken', outputCol='interest_level'),\n",
    "    VectorAssembler(inputCols=['poi_id_encoded', 'user_hash_id_encoded'],\n",
    "                    outputCol='features'),\n",
    "])\n",
    "\n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df = model.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+--------------+------------------+--------------------+--------------+---------------+--------------+--------------------+\n",
      "|user_hash_id|poiID|pictures_taken|user_hash_id_index|user_hash_id_encoded|poi_id_indexed| poi_id_encoded|interest_level|            features|\n",
      "+------------+-----+--------------+------------------+--------------------+--------------+---------------+--------------+--------------------+\n",
      "| -1861435726|   19|             7|             279.0|  (8903,[279],[1.0])|          17.0|(31,[17],[1.0])|           3.0|(8934,[17,310],[1...|\n",
      "| -1064654977|   26|             8|             181.0|  (8903,[181],[1.0])|           5.0| (31,[5],[1.0])|           3.0|(8934,[5,212],[1....|\n",
      "|  -636721096|   17|             1|            2187.0| (8903,[2187],[1.0])|           4.0| (31,[4],[1.0])|           1.0|(8934,[4,2218],[1...|\n",
      "+------------+-----+--------------+------------------+--------------------+--------------+---------------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparse_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_train_df, sagemaker_test_df = sparse_df.randomSplit([0.8, 0.2], seed=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once pyspark supports writing to protobuf directly, as one can do in scala we could do:\n",
    "#\n",
    "# sagemaker_train_df.write.format(\"sagemaker\").option(\"labelColumnName\", \"interest_level\").option(\"featuresColumnName\", \"features\").save(\"s3://mastering-ml-aws/chapter6/train-data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np \n",
    "import boto3\n",
    "import io\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "\n",
    "def spark_vector_to_sparse_matrix(row):\n",
    "    vect = row['features']\n",
    "    return csr_matrix((vect.values, vect.indices, np.array([0, vect.values.size])),(1, vect.size), dtype=np.float32)\n",
    "\n",
    "def upload_matrices_to_s3(dataframe, dataset_name):\n",
    "    features_matrices = dataframe.select(\"features\").rdd.map(spark_vector_to_sparse_matrix).collect()\n",
    "    interest_levels = dataframe.select(\"interest_level\").rdd.map(lambda r: r['interest_level']).collect()\n",
    "    \n",
    "    interest_level_vector = np.array(interest_levels, dtype=np.float32)\n",
    "    buffer = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buffer, sp.vstack(features_matrices), interest_level_vector)\n",
    "    buffer.seek(0)\n",
    "    bucket = boto3.resource('s3').Bucket('mastering-ml-aws')\n",
    "    bucket.Object('chapter6/%s-data.protobuf'%dataset_name).upload_fileobj(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_matrices_to_s3(sagemaker_train_df, 'train')\n",
    "upload_matrices_to_s3(sagemaker_test_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(8934, {22: 1.0, 858: 1.0}))]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_train_df.select(\"features\").limit(1).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8934"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dimension = len(sagemaker_train_df.select(\"features\").limit(1).collect()[0].features)\n",
    "feature_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_408c93fb63bc1870f856,\n",
       " OneHotEncoder_417081dda23913c94abf,\n",
       " StringIndexer_4c6db0dcee74ed526966,\n",
       " OneHotEncoder_4342a6d727d179d2e97a,\n",
       " Bucketizer_4760870914f95951004a,\n",
       " VectorAssembler_4ccd914048999de2d238]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-339797423', '-45351632', '-1550420186', '333791386', '344980893']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[0].labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['944065163', '94926449', '-559580957', '-554124381', '-1355542311']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[2].labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8903, 31)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.stages[0].labels), len(model.stages[2].labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "container = sagemaker.amazon.amazon_estimator.get_image_uri('us-east-1', \"factorization-machines\", \"latest\")\n",
    "\n",
    "s3_train_data = 's3://mastering-ml-aws/chapter6/train-data.protobuf'\n",
    "s3_test_data = 's3://mastering-ml-aws/chapter6/train-data.protobuf'\n",
    "s3_output_location = 's3://mastering-ml-aws/chapter6/sagemaker/output/'\n",
    "s3_model_location = 's3://mastering-ml-aws/chapter6/sagemaker/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: factorization-machines-2019-02-22-14-25-41-535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-22 14:25:41 Starting - Starting the training job...\n",
      "2019-02-22 14:25:43 Starting - Launching requested ML instances............\n",
      "2019-02-22 14:27:47 Starting - Preparing the instances for training......\n",
      "2019-02-22 14:29:10 Downloading - Downloading input data..\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:24 INFO 140042773481280] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:24 INFO 140042773481280] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'epochs': u'200', u'feature_dim': u'8934', u'mini_batch_size': u'100', u'predictor_type': u'regressor', u'num_factors': u'128'}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:24 INFO 140042773481280] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'200', u'feature_dim': u'8934', u'num_factors': u'128', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'100', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:24 WARNING 140042773481280] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:24 INFO 140042773481280] Using default worker.\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:24.292] [tensorio] [info] batch={\"data_pipeline\": \"/opt/ml/input/data/train\", \"num_examples\": 100, \"features\": [{\"name\": \"label_values\", \"shape\": [1], \"storage_type\": \"dense\"}, {\"name\": \"values\", \"shape\": [8934], \"storage_type\": \"CSR\"}]}\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:24.293] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:24.294] [tensorio] [info] batch={\"data_pipeline\": \"/opt/ml/input/data/test\", \"num_examples\": 100, \"features\": [{\"name\": \"label_values\", \"shape\": [1], \"storage_type\": \"dense\"}, {\"name\": \"values\", \"shape\": [8934], \"storage_type\": \"CSR\"}]}\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:24.296] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 4, \"num_examples\": 1}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:24 INFO 140042773481280] nvidia-smi took: 0.0252130031586 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:24 INFO 140042773481280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:24 INFO 140042773481280] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:24 INFO 140042773481280] Create Store: local\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 34.76381301879883, \"sum\": 34.76381301879883, \"min\": 34.76381301879883}}, \"EndTime\": 1550845764.330318, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845764.289398}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1550845764.330507, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845764.330449}\n",
      "\u001b[0m\n",
      "\u001b[31m[14:29:24] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.201285.0/RHEL5_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[31m[14:29:24] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.201285.0/RHEL5_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:24 INFO 140042773481280] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=1.74822960812\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:25 INFO 140042773481280] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=0.851436242606\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 200, \"sum\": 200.0, \"min\": 200}, \"update.time\": {\"count\": 1, \"max\": 829.3969631195068, \"sum\": 829.3969631195068, \"min\": 829.3969631195068}}, \"EndTime\": 1550845765.160124, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845764.330391}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:25 INFO 140042773481280] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 347, \"sum\": 347.0, \"min\": 347}, \"Total Records Seen\": {\"count\": 1, \"max\": 34660, \"sum\": 34660.0, \"min\": 34660}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1550845765.160429, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1550845764.330695}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:25 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=41644.8862326 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:25.160] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 758, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:25 INFO 140042773481280] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=0.78928838235\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:25 INFO 140042773481280] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=0.807638594993\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 658.6439609527588, \"sum\": 658.6439609527588, \"min\": 658.6439609527588}}, \"EndTime\": 1550845765.819464, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845765.160237}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:25 INFO 140042773481280] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 693, \"sum\": 693.0, \"min\": 693}, \"Total Records Seen\": {\"count\": 1, \"max\": 69220, \"sum\": 69220.0, \"min\": 69220}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1550845765.819659, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1550845765.160792}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:25 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=52441.3375159 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:25.819] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 657, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:25 INFO 140042773481280] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=0.776269844526\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:26 INFO 140042773481280] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=0.780867355151\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 612.4401092529297, \"sum\": 612.4401092529297, \"min\": 612.4401092529297}}, \"EndTime\": 1550845766.432437, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845765.819531}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:26 INFO 140042773481280] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1039, \"sum\": 1039.0, \"min\": 1039}, \"Total Records Seen\": {\"count\": 1, \"max\": 103780, \"sum\": 103780.0, \"min\": 103780}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1550845766.432704, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1550845765.819967}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:26 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56390.6029009 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:26.432] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 3, \"duration\": 611, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:26 INFO 140042773481280] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=0.753051779579\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:26 INFO 140042773481280] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=0.74443345783\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 565.3359889984131, \"sum\": 565.3359889984131, \"min\": 565.3359889984131}}, \"EndTime\": 1550845766.998339, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845766.432515}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:26 INFO 140042773481280] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1385, \"sum\": 1385.0, \"min\": 1385}, \"Total Records Seen\": {\"count\": 1, \"max\": 138340, \"sum\": 138340.0, \"min\": 138340}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1550845766.998538, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 3}, \"StartTime\": 1550845766.43297}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:26 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=61092.4459797 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:26.998] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 564, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:27 INFO 140042773481280] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=0.723753864495\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:27 INFO 140042773481280] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=0.707203425014\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 582.4620723724365, \"sum\": 582.4620723724365, \"min\": 582.4620723724365}}, \"EndTime\": 1550845767.581312, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845766.998409}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:27 INFO 140042773481280] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1731, \"sum\": 1731.0, \"min\": 1731}, \"Total Records Seen\": {\"count\": 1, \"max\": 172900, \"sum\": 172900.0, \"min\": 172900}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1550845767.581537, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 4}, \"StartTime\": 1550845766.998819}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:27 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59294.5310826 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:27.581] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 5, \"duration\": 581, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:27 INFO 140042773481280] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=0.695495553941\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:28 INFO 140042773481280] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=0.676688145273\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 755.483865737915, \"sum\": 755.483865737915, \"min\": 755.483865737915}}, \"EndTime\": 1550845768.337349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845767.581384}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:28 INFO 140042773481280] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2077, \"sum\": 2077.0, \"min\": 2077}, \"Total Records Seen\": {\"count\": 1, \"max\": 207460, \"sum\": 207460.0, \"min\": 207460}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1550845768.337567, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 5}, \"StartTime\": 1550845767.581832}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:28 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=45722.5743655 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:28.337] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 754, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:28 INFO 140042773481280] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=0.672601635141\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:29 INFO 140042773481280] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=0.655101206288\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 742.7470684051514, \"sum\": 742.7470684051514, \"min\": 742.7470684051514}}, \"EndTime\": 1550845769.080624, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845768.337419}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:29 INFO 140042773481280] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2423, \"sum\": 2423.0, \"min\": 2423}, \"Total Records Seen\": {\"count\": 1, \"max\": 242020, \"sum\": 242020.0, \"min\": 242020}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1550845769.080844, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 6}, \"StartTime\": 1550845768.337844}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:29 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=46506.1162403 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:29.081] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 7, \"duration\": 741, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:29 INFO 140042773481280] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=0.655642738939\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:29 INFO 140042773481280] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=0.640594790198\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 697.1919536590576, \"sum\": 697.1919536590576, \"min\": 697.1919536590576}}, \"EndTime\": 1550845769.778394, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845769.080695}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:29 INFO 140042773481280] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2769, \"sum\": 2769.0, \"min\": 2769}, \"Total Records Seen\": {\"count\": 1, \"max\": 276580, \"sum\": 276580.0, \"min\": 276580}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1550845769.778772, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 7}, \"StartTime\": 1550845769.081164}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:29 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=49531.6262438 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:29.778] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 696, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:29 INFO 140042773481280] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=0.643160414837\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-02-22 14:29:22 Training - Training image download completed. Training in progress.\u001b[31m[02/22/2019 14:29:30 INFO 140042773481280] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=0.630365094681\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 604.363203048706, \"sum\": 604.363203048706, \"min\": 604.363203048706}}, \"EndTime\": 1550845770.38344, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845769.778471}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:30 INFO 140042773481280] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3115, \"sum\": 3115.0, \"min\": 3115}, \"Total Records Seen\": {\"count\": 1, \"max\": 311140, \"sum\": 311140.0, \"min\": 311140}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1550845770.383635, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 8}, \"StartTime\": 1550845769.779052}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:30 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57150.9015052 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:30.383] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 9, \"duration\": 603, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:30 INFO 140042773481280] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=0.63345944337\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:30 INFO 140042773481280] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=0.622430225958\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 577.3229598999023, \"sum\": 577.3229598999023, \"min\": 577.3229598999023}}, \"EndTime\": 1550845770.961249, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845770.3835}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:30 INFO 140042773481280] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3461, \"sum\": 3461.0, \"min\": 3461}, \"Total Records Seen\": {\"count\": 1, \"max\": 345700, \"sum\": 345700.0, \"min\": 345700}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1550845770.961476, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 9}, \"StartTime\": 1550845770.383897}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:30 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59825.1023904 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:30.961] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 576, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:30 INFO 140042773481280] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=0.625386111203\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:31 INFO 140042773481280] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=0.61574381627\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 587.4989032745361, \"sum\": 587.4989032745361, \"min\": 587.4989032745361}}, \"EndTime\": 1550845771.549213, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845770.961323}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:31 INFO 140042773481280] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3807, \"sum\": 3807.0, \"min\": 3807}, \"Total Records Seen\": {\"count\": 1, \"max\": 380260, \"sum\": 380260.0, \"min\": 380260}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1550845771.549433, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 10}, \"StartTime\": 1550845770.961684}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:31 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58789.9023015 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:31.549] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 11, \"duration\": 586, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:31 INFO 140042773481280] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=0.618330904124\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:32 INFO 140042773481280] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=0.609796012294\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 602.9341220855713, \"sum\": 602.9341220855713, \"min\": 602.9341220855713}}, \"EndTime\": 1550845772.152655, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845771.549287}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:32 INFO 140042773481280] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4153, \"sum\": 4153.0, \"min\": 4153}, \"Total Records Seen\": {\"count\": 1, \"max\": 414820, \"sum\": 414820.0, \"min\": 414820}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1550845772.152947, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 11}, \"StartTime\": 1550845771.54969}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:32 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57272.8827526 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:32.153] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 601, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:32 INFO 140042773481280] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=0.6119906429\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:32 INFO 140042773481280] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=0.604323655337\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 609.5209121704102, \"sum\": 609.5209121704102, \"min\": 609.5209121704102}}, \"EndTime\": 1550845772.762824, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845772.152751}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:32 INFO 140042773481280] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4499, \"sum\": 4499.0, \"min\": 4499}, \"Total Records Seen\": {\"count\": 1, \"max\": 449380, \"sum\": 449380.0, \"min\": 449380}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1550845772.763153, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 12}, \"StartTime\": 1550845772.153271}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:32 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56652.2046442 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:32.763] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 13, \"duration\": 608, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:32 INFO 140042773481280] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=0.606187860509\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:33 INFO 140042773481280] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=0.599174645393\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 601.4358997344971, \"sum\": 601.4358997344971, \"min\": 601.4358997344971}}, \"EndTime\": 1550845773.364965, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845772.762977}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:33 INFO 140042773481280] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4845, \"sum\": 4845.0, \"min\": 4845}, \"Total Records Seen\": {\"count\": 1, \"max\": 483940, \"sum\": 483940.0, \"min\": 483940}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1550845773.365195, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 13}, \"StartTime\": 1550845772.763496}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:33 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57424.671663 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:33.365] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 600, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:33 INFO 140042773481280] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=0.600789885341\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:33 INFO 140042773481280] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=0.594250765094\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.0950527191162, \"sum\": 580.0950527191162, \"min\": 580.0950527191162}}, \"EndTime\": 1550845773.945599, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845773.365039}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:33 INFO 140042773481280] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5191, \"sum\": 5191.0, \"min\": 5191}, \"Total Records Seen\": {\"count\": 1, \"max\": 518500, \"sum\": 518500.0, \"min\": 518500}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1550845773.945785, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 14}, \"StartTime\": 1550845773.365472}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:33 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59543.0877181 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:33.945] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 15, \"duration\": 579, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:33 INFO 140042773481280] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=0.59568532248\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:34 INFO 140042773481280] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=0.589483079972\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 615.415096282959, \"sum\": 615.415096282959, \"min\": 615.415096282959}}, \"EndTime\": 1550845774.56161, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845773.945661}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:34 INFO 140042773481280] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5537, \"sum\": 5537.0, \"min\": 5537}, \"Total Records Seen\": {\"count\": 1, \"max\": 553060, \"sum\": 553060.0, \"min\": 553060}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1550845774.561837, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 15}, \"StartTime\": 1550845773.946011}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:34 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56109.6350855 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:34.562] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 614, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:34 INFO 140042773481280] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=0.590780538434\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:35 INFO 140042773481280] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=0.584820644999\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 582.9989910125732, \"sum\": 582.9989910125732, \"min\": 582.9989910125732}}, \"EndTime\": 1550845775.145121, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845774.561686}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:35 INFO 140042773481280] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5883, \"sum\": 5883.0, \"min\": 5883}, \"Total Records Seen\": {\"count\": 1, \"max\": 587620, \"sum\": 587620.0, \"min\": 587620}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 18, \"sum\": 18.0, \"min\": 18}}, \"EndTime\": 1550845775.145325, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 16}, \"StartTime\": 1550845774.562092}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:35 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59243.3978305 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:35.145] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 17, \"duration\": 582, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:35 INFO 140042773481280] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=0.585999638632\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:35 INFO 140042773481280] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=0.580224737908\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 569.8659420013428, \"sum\": 569.8659420013428, \"min\": 569.8659420013428}}, \"EndTime\": 1550845775.715478, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845775.145185}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:35 INFO 140042773481280] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6229, \"sum\": 6229.0, \"min\": 6229}, \"Total Records Seen\": {\"count\": 1, \"max\": 622180, \"sum\": 622180.0, \"min\": 622180}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}}, \"EndTime\": 1550845775.715746, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 17}, \"StartTime\": 1550845775.14558}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:35 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60601.0669255 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:35.715] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 568, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:35 INFO 140042773481280] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=0.58128301055\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:36 INFO 140042773481280] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=0.575665498857\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 606.6930294036865, \"sum\": 606.6930294036865, \"min\": 606.6930294036865}}, \"EndTime\": 1550845776.322746, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845775.715573}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:36 INFO 140042773481280] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6575, \"sum\": 6575.0, \"min\": 6575}, \"Total Records Seen\": {\"count\": 1, \"max\": 656740, \"sum\": 656740.0, \"min\": 656740}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}}, \"EndTime\": 1550845776.323084, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 18}, \"StartTime\": 1550845775.716021}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:36 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56918.1221888 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:36.323] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 19, \"duration\": 605, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:36 INFO 140042773481280] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=0.576585358784\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:36 INFO 140042773481280] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=0.571119661807\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.0319747924805, \"sum\": 572.0319747924805, \"min\": 572.0319747924805}}, \"EndTime\": 1550845776.895406, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845776.322816}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:36 INFO 140042773481280] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6921, \"sum\": 6921.0, \"min\": 6921}, \"Total Records Seen\": {\"count\": 1, \"max\": 691300, \"sum\": 691300.0, \"min\": 691300}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 21, \"sum\": 21.0, \"min\": 21}}, \"EndTime\": 1550845776.895591, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 19}, \"StartTime\": 1550845776.323342}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:36 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60380.4169621 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:36.895] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 570, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:36 INFO 140042773481280] #quality_metric: host=algo-1, epoch=20, batch=0 train rmse <loss>=0.571873999423\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:37 INFO 140042773481280] #quality_metric: host=algo-1, epoch=20, train rmse <loss>=0.566569048838\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 573.0319023132324, \"sum\": 573.0319023132324, \"min\": 573.0319023132324}}, \"EndTime\": 1550845777.468926, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845776.895469}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:37 INFO 140042773481280] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7267, \"sum\": 7267.0, \"min\": 7267}, \"Total Records Seen\": {\"count\": 1, \"max\": 725860, \"sum\": 725860.0, \"min\": 725860}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}}, \"EndTime\": 1550845777.469151, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 20}, \"StartTime\": 1550845776.895862}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:37 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60269.9541723 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:37.469] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 21, \"duration\": 572, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:37 INFO 140042773481280] #quality_metric: host=algo-1, epoch=21, batch=0 train rmse <loss>=0.567126629718\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:38 INFO 140042773481280] #quality_metric: host=algo-1, epoch=21, train rmse <loss>=0.561999428297\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 586.3640308380127, \"sum\": 586.3640308380127, \"min\": 586.3640308380127}}, \"EndTime\": 1550845778.055821, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845777.468998}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:38 INFO 140042773481280] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7613, \"sum\": 7613.0, \"min\": 7613}, \"Total Records Seen\": {\"count\": 1, \"max\": 760420, \"sum\": 760420.0, \"min\": 760420}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 23, \"sum\": 23.0, \"min\": 23}}, \"EndTime\": 1550845778.056101, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 21}, \"StartTime\": 1550845777.469426}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:38 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58893.2070814 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:38.056] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 585, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:38 INFO 140042773481280] #quality_metric: host=algo-1, epoch=22, batch=0 train rmse <loss>=0.562329584374\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:38 INFO 140042773481280] #quality_metric: host=algo-1, epoch=22, train rmse <loss>=0.557399643876\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 614.4459247589111, \"sum\": 614.4459247589111, \"min\": 614.4459247589111}}, \"EndTime\": 1550845778.670947, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845778.05592}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:38 INFO 140042773481280] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7959, \"sum\": 7959.0, \"min\": 7959}, \"Total Records Seen\": {\"count\": 1, \"max\": 794980, \"sum\": 794980.0, \"min\": 794980}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 24, \"sum\": 24.0, \"min\": 24}}, \"EndTime\": 1550845778.671154, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 22}, \"StartTime\": 1550845778.056454}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:38 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56210.8326741 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:38.671] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 23, \"duration\": 613, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:38 INFO 140042773481280] #quality_metric: host=algo-1, epoch=23, batch=0 train rmse <loss>=0.557475473865\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:39 INFO 140042773481280] #quality_metric: host=algo-1, epoch=23, train rmse <loss>=0.552760819087\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 573.6470222473145, \"sum\": 573.6470222473145, \"min\": 573.6470222473145}}, \"EndTime\": 1550845779.245077, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845778.671012}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:39 INFO 140042773481280] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8305, \"sum\": 8305.0, \"min\": 8305}, \"Total Records Seen\": {\"count\": 1, \"max\": 829540, \"sum\": 829540.0, \"min\": 829540}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 25, \"sum\": 25.0, \"min\": 25}}, \"EndTime\": 1550845779.245273, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 23}, \"StartTime\": 1550845778.671399}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:39 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60208.8715692 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:39.245] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 572, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:39 INFO 140042773481280] #quality_metric: host=algo-1, epoch=24, batch=0 train rmse <loss>=0.552560878524\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:39 INFO 140042773481280] #quality_metric: host=algo-1, epoch=24, train rmse <loss>=0.548075734644\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 575.3769874572754, \"sum\": 575.3769874572754, \"min\": 575.3769874572754}}, \"EndTime\": 1550845779.820964, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845779.245133}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:39 INFO 140042773481280] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8651, \"sum\": 8651.0, \"min\": 8651}, \"Total Records Seen\": {\"count\": 1, \"max\": 864100, \"sum\": 864100.0, \"min\": 864100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 26, \"sum\": 26.0, \"min\": 26}}, \"EndTime\": 1550845779.821195, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 24}, \"StartTime\": 1550845779.245555}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:39 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60024.5995804 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:39.821] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 25, \"duration\": 574, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:39 INFO 140042773481280] #quality_metric: host=algo-1, epoch=25, batch=0 train rmse <loss>=0.547584744518\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/22/2019 14:29:40 INFO 140042773481280] #quality_metric: host=algo-1, epoch=25, train rmse <loss>=0.543338305246\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.0069828033447, \"sum\": 578.0069828033447, \"min\": 578.0069828033447}}, \"EndTime\": 1550845780.3995, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845779.821034}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:40 INFO 140042773481280] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8997, \"sum\": 8997.0, \"min\": 8997}, \"Total Records Seen\": {\"count\": 1, \"max\": 898660, \"sum\": 898660.0, \"min\": 898660}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 27, \"sum\": 27.0, \"min\": 27}}, \"EndTime\": 1550845780.399726, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 25}, \"StartTime\": 1550845779.821461}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:40 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59751.5652499 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:40.399] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 576, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:40 INFO 140042773481280] #quality_metric: host=algo-1, epoch=26, batch=0 train rmse <loss>=0.542546292628\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:41 INFO 140042773481280] #quality_metric: host=algo-1, epoch=26, train rmse <loss>=0.538543147527\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 600.8701324462891, \"sum\": 600.8701324462891, \"min\": 600.8701324462891}}, \"EndTime\": 1550845781.000902, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845780.399571}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:41 INFO 140042773481280] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9343, \"sum\": 9343.0, \"min\": 9343}, \"Total Records Seen\": {\"count\": 1, \"max\": 933220, \"sum\": 933220.0, \"min\": 933220}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 28, \"sum\": 28.0, \"min\": 28}}, \"EndTime\": 1550845781.00107, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 26}, \"StartTime\": 1550845780.400006}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:41 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57487.5961837 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:41.001] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 27, \"duration\": 599, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:41 INFO 140042773481280] #quality_metric: host=algo-1, epoch=27, batch=0 train rmse <loss>=0.537444391257\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:41 INFO 140042773481280] #quality_metric: host=algo-1, epoch=27, train rmse <loss>=0.53368525749\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.8989582061768, \"sum\": 574.8989582061768, \"min\": 574.8989582061768}}, \"EndTime\": 1550845781.576269, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845781.000954}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:41 INFO 140042773481280] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9689, \"sum\": 9689.0, \"min\": 9689}, \"Total Records Seen\": {\"count\": 1, \"max\": 967780, \"sum\": 967780.0, \"min\": 967780}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 29, \"sum\": 29.0, \"min\": 29}}, \"EndTime\": 1550845781.576473, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 27}, \"StartTime\": 1550845781.00133}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:41 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60076.5430627 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:41.576] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 573, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:41 INFO 140042773481280] #quality_metric: host=algo-1, epoch=28, batch=0 train rmse <loss>=0.53227640965\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:42 INFO 140042773481280] #quality_metric: host=algo-1, epoch=28, train rmse <loss>=0.528759810572\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.7839469909668, \"sum\": 572.7839469909668, \"min\": 572.7839469909668}}, \"EndTime\": 1550845782.149534, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845781.576333}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:42 INFO 140042773481280] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 10035, \"sum\": 10035.0, \"min\": 10035}, \"Total Records Seen\": {\"count\": 1, \"max\": 1002340, \"sum\": 1002340.0, \"min\": 1002340}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}}, \"EndTime\": 1550845782.149737, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 28}, \"StartTime\": 1550845781.576719}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:42 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60300.667398 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:42.149] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 29, \"duration\": 571, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:42 INFO 140042773481280] #quality_metric: host=algo-1, epoch=29, batch=0 train rmse <loss>=0.5270379973\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:42 INFO 140042773481280] #quality_metric: host=algo-1, epoch=29, train rmse <loss>=0.523761978344\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 614.6988868713379, \"sum\": 614.6988868713379, \"min\": 614.6988868713379}}, \"EndTime\": 1550845782.764704, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845782.149599}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:42 INFO 140042773481280] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 10381, \"sum\": 10381.0, \"min\": 10381}, \"Total Records Seen\": {\"count\": 1, \"max\": 1036900, \"sum\": 1036900.0, \"min\": 1036900}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}}, \"EndTime\": 1550845782.764937, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 29}, \"StartTime\": 1550845782.149974}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:42 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56187.3665825 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:42.765] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 613, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:42 INFO 140042773481280] #quality_metric: host=algo-1, epoch=30, batch=0 train rmse <loss>=0.521723011293\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:43 INFO 140042773481280] #quality_metric: host=algo-1, epoch=30, train rmse <loss>=0.518686985737\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 635.3909969329834, \"sum\": 635.3909969329834, \"min\": 635.3909969329834}}, \"EndTime\": 1550845783.40062, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845782.764779}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:43 INFO 140042773481280] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 10727, \"sum\": 10727.0, \"min\": 10727}, \"Total Records Seen\": {\"count\": 1, \"max\": 1071460, \"sum\": 1071460.0, \"min\": 1071460}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 32, \"sum\": 32.0, \"min\": 32}}, \"EndTime\": 1550845783.400895, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 30}, \"StartTime\": 1550845782.765198}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:43 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=54353.0366839 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:43.401] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 31, \"duration\": 634, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:43 INFO 140042773481280] #quality_metric: host=algo-1, epoch=31, batch=0 train rmse <loss>=0.516323933699\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:43 INFO 140042773481280] #quality_metric: host=algo-1, epoch=31, train rmse <loss>=0.513530132345\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 576.3680934906006, \"sum\": 576.3680934906006, \"min\": 576.3680934906006}}, \"EndTime\": 1550845783.977609, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845783.40072}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:43 INFO 140042773481280] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 11073, \"sum\": 11073.0, \"min\": 11073}, \"Total Records Seen\": {\"count\": 1, \"max\": 1106020, \"sum\": 1106020.0, \"min\": 1106020}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 33, \"sum\": 33.0, \"min\": 33}}, \"EndTime\": 1550845783.977957, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 31}, \"StartTime\": 1550845783.40121}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:43 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59908.0545225 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:43.978] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 575, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:43 INFO 140042773481280] #quality_metric: host=algo-1, epoch=32, batch=0 train rmse <loss>=0.510832030817\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:44 INFO 140042773481280] #quality_metric: host=algo-1, epoch=32, train rmse <loss>=0.50828699416\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 581.5811157226562, \"sum\": 581.5811157226562, \"min\": 581.5811157226562}}, \"EndTime\": 1550845784.559918, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845783.977709}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:44 INFO 140042773481280] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 11419, \"sum\": 11419.0, \"min\": 11419}, \"Total Records Seen\": {\"count\": 1, \"max\": 1140580, \"sum\": 1140580.0, \"min\": 1140580}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 34, \"sum\": 34.0, \"min\": 34}}, \"EndTime\": 1550845784.560121, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 32}, \"StartTime\": 1550845783.978304}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:44 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59383.7769199 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:44.560] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 33, \"duration\": 580, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:44 INFO 140042773481280] #quality_metric: host=algo-1, epoch=33, batch=0 train rmse <loss>=0.505238556368\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:45 INFO 140042773481280] #quality_metric: host=algo-1, epoch=33, train rmse <loss>=0.502953699217\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 604.2389869689941, \"sum\": 604.2389869689941, \"min\": 604.2389869689941}}, \"EndTime\": 1550845785.164632, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845784.559983}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:45 INFO 140042773481280] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 11765, \"sum\": 11765.0, \"min\": 11765}, \"Total Records Seen\": {\"count\": 1, \"max\": 1175140, \"sum\": 1175140.0, \"min\": 1175140}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 35, \"sum\": 35.0, \"min\": 35}}, \"EndTime\": 1550845785.164836, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 33}, \"StartTime\": 1550845784.560362}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:45 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57162.3278497 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:45.165] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 603, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:45 INFO 140042773481280] #quality_metric: host=algo-1, epoch=34, batch=0 train rmse <loss>=0.499535363795\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:45 INFO 140042773481280] #quality_metric: host=algo-1, epoch=34, train rmse <loss>=0.497527159307\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 577.0220756530762, \"sum\": 577.0220756530762, \"min\": 577.0220756530762}}, \"EndTime\": 1550845785.742137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845785.164696}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:45 INFO 140042773481280] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 12111, \"sum\": 12111.0, \"min\": 12111}, \"Total Records Seen\": {\"count\": 1, \"max\": 1209700, \"sum\": 1209700.0, \"min\": 1209700}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 36, \"sum\": 36.0, \"min\": 36}}, \"EndTime\": 1550845785.742375, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 34}, \"StartTime\": 1550845785.165084}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:45 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59853.485455 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:45.742] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 35, \"duration\": 575, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:45 INFO 140042773481280] #quality_metric: host=algo-1, epoch=35, batch=0 train rmse <loss>=0.49371577277\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:46 INFO 140042773481280] #quality_metric: host=algo-1, epoch=35, train rmse <loss>=0.492005391758\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.0170269012451, \"sum\": 571.0170269012451, \"min\": 571.0170269012451}}, \"EndTime\": 1550845786.313667, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845785.742202}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:46 INFO 140042773481280] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 12457, \"sum\": 12457.0, \"min\": 12457}, \"Total Records Seen\": {\"count\": 1, \"max\": 1244260, \"sum\": 1244260.0, \"min\": 1244260}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 37, \"sum\": 37.0, \"min\": 37}}, \"EndTime\": 1550845786.313873, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 35}, \"StartTime\": 1550845785.74262}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:46 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60486.7166539 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:46.314] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 569, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:46 INFO 140042773481280] #quality_metric: host=algo-1, epoch=36, batch=0 train rmse <loss>=0.487775186973\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:46 INFO 140042773481280] #quality_metric: host=algo-1, epoch=36, train rmse <loss>=0.486387727887\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 593.6479568481445, \"sum\": 593.6479568481445, \"min\": 593.6479568481445}}, \"EndTime\": 1550845786.907804, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845786.313731}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:46 INFO 140042773481280] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 12803, \"sum\": 12803.0, \"min\": 12803}, \"Total Records Seen\": {\"count\": 1, \"max\": 1278820, \"sum\": 1278820.0, \"min\": 1278820}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 38, \"sum\": 38.0, \"min\": 38}}, \"EndTime\": 1550845786.908034, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 36}, \"StartTime\": 1550845786.314108}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:46 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58178.0954063 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:46.908] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 37, \"duration\": 592, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:46 INFO 140042773481280] #quality_metric: host=algo-1, epoch=37, batch=0 train rmse <loss>=0.48171148591\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:47 INFO 140042773481280] #quality_metric: host=algo-1, epoch=37, train rmse <loss>=0.480674956477\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 567.5690174102783, \"sum\": 567.5690174102783, \"min\": 567.5690174102783}}, \"EndTime\": 1550845787.475886, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845786.90787}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:47 INFO 140042773481280] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 13149, \"sum\": 13149.0, \"min\": 13149}, \"Total Records Seen\": {\"count\": 1, \"max\": 1313380, \"sum\": 1313380.0, \"min\": 1313380}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 39, \"sum\": 39.0, \"min\": 39}}, \"EndTime\": 1550845787.476149, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 37}, \"StartTime\": 1550845786.908285}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:47 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60846.3646018 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:47.476] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 566, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:47 INFO 140042773481280] #quality_metric: host=algo-1, epoch=38, batch=0 train rmse <loss>=0.475525454958\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:48 INFO 140042773481280] #quality_metric: host=algo-1, epoch=38, train rmse <loss>=0.474869353603\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 573.1940269470215, \"sum\": 573.1940269470215, \"min\": 573.1940269470215}}, \"EndTime\": 1550845788.049651, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845787.475954}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:48 INFO 140042773481280] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 13495, \"sum\": 13495.0, \"min\": 13495}, \"Total Records Seen\": {\"count\": 1, \"max\": 1347940, \"sum\": 1347940.0, \"min\": 1347940}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 40, \"sum\": 40.0, \"min\": 40}}, \"EndTime\": 1550845788.04986, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 38}, \"StartTime\": 1550845787.476425}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:48 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60254.7219984 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:48.050] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 39, \"duration\": 572, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:48 INFO 140042773481280] #quality_metric: host=algo-1, epoch=39, batch=0 train rmse <loss>=0.469220446705\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:48 INFO 140042773481280] #quality_metric: host=algo-1, epoch=39, train rmse <loss>=0.46897465653\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 628.8981437683105, \"sum\": 628.8981437683105, \"min\": 628.8981437683105}}, \"EndTime\": 1550845788.679072, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845788.049726}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:48 INFO 140042773481280] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 13841, \"sum\": 13841.0, \"min\": 13841}, \"Total Records Seen\": {\"count\": 1, \"max\": 1382500, \"sum\": 1382500.0, \"min\": 1382500}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 41, \"sum\": 41.0, \"min\": 41}}, \"EndTime\": 1550845788.679311, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 39}, \"StartTime\": 1550845788.050143}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:48 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=54916.4883185 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:48.679] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 627, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:48 INFO 140042773481280] #quality_metric: host=algo-1, epoch=40, batch=0 train rmse <loss>=0.462802272686\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:49 INFO 140042773481280] #quality_metric: host=algo-1, epoch=40, train rmse <loss>=0.462995931021\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 794.0530776977539, \"sum\": 794.0530776977539, \"min\": 794.0530776977539}}, \"EndTime\": 1550845789.473707, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845788.679139}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:49 INFO 140042773481280] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 14187, \"sum\": 14187.0, \"min\": 14187}, \"Total Records Seen\": {\"count\": 1, \"max\": 1417060, \"sum\": 1417060.0, \"min\": 1417060}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 42, \"sum\": 42.0, \"min\": 42}}, \"EndTime\": 1550845789.473946, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 40}, \"StartTime\": 1550845788.679623}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:49 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=43500.7077024 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:49.474] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 41, \"duration\": 792, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:49 INFO 140042773481280] #quality_metric: host=algo-1, epoch=41, batch=0 train rmse <loss>=0.456279325196\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:50 INFO 140042773481280] #quality_metric: host=algo-1, epoch=41, train rmse <loss>=0.456939383656\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 607.586145401001, \"sum\": 607.586145401001, \"min\": 607.586145401001}}, \"EndTime\": 1550845790.082056, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845789.473773}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:50 INFO 140042773481280] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 14533, \"sum\": 14533.0, \"min\": 14533}, \"Total Records Seen\": {\"count\": 1, \"max\": 1451620, \"sum\": 1451620.0, \"min\": 1451620}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 43, \"sum\": 43.0, \"min\": 43}}, \"EndTime\": 1550845790.082316, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 41}, \"StartTime\": 1550845789.474286}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:50 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56825.8346045 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:50.082] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 606, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:50 INFO 140042773481280] #quality_metric: host=algo-1, epoch=42, batch=0 train rmse <loss>=0.44966144542\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/22/2019 14:29:50 INFO 140042773481280] #quality_metric: host=algo-1, epoch=42, train rmse <loss>=0.450812121802\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 570.5058574676514, \"sum\": 570.5058574676514, \"min\": 570.5058574676514}}, \"EndTime\": 1550845790.653091, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845790.082126}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:50 INFO 140042773481280] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 14879, \"sum\": 14879.0, \"min\": 14879}, \"Total Records Seen\": {\"count\": 1, \"max\": 1486180, \"sum\": 1486180.0, \"min\": 1486180}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 44, \"sum\": 44.0, \"min\": 44}}, \"EndTime\": 1550845790.65332, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 42}, \"StartTime\": 1550845790.082555}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:50 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60536.3283337 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:50.653] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 43, \"duration\": 569, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:50 INFO 140042773481280] #quality_metric: host=algo-1, epoch=43, batch=0 train rmse <loss>=0.442960138254\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:51 INFO 140042773481280] #quality_metric: host=algo-1, epoch=43, train rmse <loss>=0.444621954996\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 608.6850166320801, \"sum\": 608.6850166320801, \"min\": 608.6850166320801}}, \"EndTime\": 1550845791.262323, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845790.653165}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:51 INFO 140042773481280] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 15225, \"sum\": 15225.0, \"min\": 15225}, \"Total Records Seen\": {\"count\": 1, \"max\": 1520740, \"sum\": 1520740.0, \"min\": 1520740}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}}, \"EndTime\": 1550845791.262532, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 43}, \"StartTime\": 1550845790.653607}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:51 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56744.4839978 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:51.262] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 607, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:51 INFO 140042773481280] #quality_metric: host=algo-1, epoch=44, batch=0 train rmse <loss>=0.436187956587\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:51 INFO 140042773481280] #quality_metric: host=algo-1, epoch=44, train rmse <loss>=0.438377115424\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 585.9839916229248, \"sum\": 585.9839916229248, \"min\": 585.9839916229248}}, \"EndTime\": 1550845791.848795, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845791.262389}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:51 INFO 140042773481280] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 15571, \"sum\": 15571.0, \"min\": 15571}, \"Total Records Seen\": {\"count\": 1, \"max\": 1555300, \"sum\": 1555300.0, \"min\": 1555300}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 46, \"sum\": 46.0, \"min\": 46}}, \"EndTime\": 1550845791.849021, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 44}, \"StartTime\": 1550845791.262779}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:51 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58942.2034127 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:51.849] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 45, \"duration\": 584, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:51 INFO 140042773481280] #quality_metric: host=algo-1, epoch=45, batch=0 train rmse <loss>=0.429357872501\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:52 INFO 140042773481280] #quality_metric: host=algo-1, epoch=45, train rmse <loss>=0.432086059403\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 575.6490230560303, \"sum\": 575.6490230560303, \"min\": 575.6490230560303}}, \"EndTime\": 1550845792.424907, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845791.848867}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:52 INFO 140042773481280] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 15917, \"sum\": 15917.0, \"min\": 15917}, \"Total Records Seen\": {\"count\": 1, \"max\": 1589860, \"sum\": 1589860.0, \"min\": 1589860}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 47, \"sum\": 47.0, \"min\": 47}}, \"EndTime\": 1550845792.425143, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 45}, \"StartTime\": 1550845791.84923}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:52 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59997.8171586 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:52.425] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 574, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:52 INFO 140042773481280] #quality_metric: host=algo-1, epoch=46, batch=0 train rmse <loss>=0.42248353373\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:52 INFO 140042773481280] #quality_metric: host=algo-1, epoch=46, train rmse <loss>=0.425757274067\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.3241100311279, \"sum\": 571.3241100311279, \"min\": 571.3241100311279}}, \"EndTime\": 1550845792.996748, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845792.424987}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:52 INFO 140042773481280] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 16263, \"sum\": 16263.0, \"min\": 16263}, \"Total Records Seen\": {\"count\": 1, \"max\": 1624420, \"sum\": 1624420.0, \"min\": 1624420}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 48, \"sum\": 48.0, \"min\": 48}}, \"EndTime\": 1550845792.996954, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 46}, \"StartTime\": 1550845792.425394}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:52 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60454.3512826 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:52.997] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 47, \"duration\": 570, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:53 INFO 140042773481280] #quality_metric: host=algo-1, epoch=47, batch=0 train rmse <loss>=0.415578119603\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:53 INFO 140042773481280] #quality_metric: host=algo-1, epoch=47, train rmse <loss>=0.419399138388\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 645.3678607940674, \"sum\": 645.3678607940674, \"min\": 645.3678607940674}}, \"EndTime\": 1550845793.642586, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845792.996814}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:53 INFO 140042773481280] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 16609, \"sum\": 16609.0, \"min\": 16609}, \"Total Records Seen\": {\"count\": 1, \"max\": 1658980, \"sum\": 1658980.0, \"min\": 1658980}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 49, \"sum\": 49.0, \"min\": 49}}, \"EndTime\": 1550845793.642804, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 47}, \"StartTime\": 1550845792.997187}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:53 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=53520.3258292 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:53.643] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 644, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:53 INFO 140042773481280] #quality_metric: host=algo-1, epoch=48, batch=0 train rmse <loss>=0.408654733924\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:54 INFO 140042773481280] #quality_metric: host=algo-1, epoch=48, train rmse <loss>=0.413019820907\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.5830535888672, \"sum\": 574.5830535888672, \"min\": 574.5830535888672}}, \"EndTime\": 1550845794.217694, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845793.642652}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:54 INFO 140042773481280] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 16955, \"sum\": 16955.0, \"min\": 16955}, \"Total Records Seen\": {\"count\": 1, \"max\": 1693540, \"sum\": 1693540.0, \"min\": 1693540}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}}, \"EndTime\": 1550845794.217908, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 48}, \"StartTime\": 1550845793.643078}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:54 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60110.4991379 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:54.218] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 49, \"duration\": 573, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:54 INFO 140042773481280] #quality_metric: host=algo-1, epoch=49, batch=0 train rmse <loss>=0.401725456927\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:54 INFO 140042773481280] #quality_metric: host=algo-1, epoch=49, train rmse <loss>=0.406627209808\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 593.8010215759277, \"sum\": 593.8010215759277, \"min\": 593.8010215759277}}, \"EndTime\": 1550845794.811982, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845794.217771}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:54 INFO 140042773481280] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 17301, \"sum\": 17301.0, \"min\": 17301}, \"Total Records Seen\": {\"count\": 1, \"max\": 1728100, \"sum\": 1728100.0, \"min\": 1728100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 51, \"sum\": 51.0, \"min\": 51}}, \"EndTime\": 1550845794.812286, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 49}, \"StartTime\": 1550845794.21815}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:54 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58156.9480702 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:54.812] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 593, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:54 INFO 140042773481280] #quality_metric: host=algo-1, epoch=50, batch=0 train rmse <loss>=0.394801549192\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:55 INFO 140042773481280] #quality_metric: host=algo-1, epoch=50, train rmse <loss>=0.400228899995\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 614.1819953918457, \"sum\": 614.1819953918457, \"min\": 614.1819953918457}}, \"EndTime\": 1550845795.426738, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845794.812055}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:55 INFO 140042773481280] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 17647, \"sum\": 17647.0, \"min\": 17647}, \"Total Records Seen\": {\"count\": 1, \"max\": 1762660, \"sum\": 1762660.0, \"min\": 1762660}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 52, \"sum\": 52.0, \"min\": 52}}, \"EndTime\": 1550845795.426946, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 50}, \"StartTime\": 1550845794.812526}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:55 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56237.7218304 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:55.427] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 51, \"duration\": 612, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:55 INFO 140042773481280] #quality_metric: host=algo-1, epoch=51, batch=0 train rmse <loss>=0.387893243418\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:55 INFO 140042773481280] #quality_metric: host=algo-1, epoch=51, train rmse <loss>=0.39383221986\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 569.4670677185059, \"sum\": 569.4670677185059, \"min\": 569.4670677185059}}, \"EndTime\": 1550845795.996682, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845795.426803}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:55 INFO 140042773481280] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 17993, \"sum\": 17993.0, \"min\": 17993}, \"Total Records Seen\": {\"count\": 1, \"max\": 1797220, \"sum\": 1797220.0, \"min\": 1797220}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 53, \"sum\": 53.0, \"min\": 53}}, \"EndTime\": 1550845795.996898, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 51}, \"StartTime\": 1550845795.427185}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:55 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60643.7109705 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:55.997] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 568, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:56 INFO 140042773481280] #quality_metric: host=algo-1, epoch=52, batch=0 train rmse <loss>=0.381008747251\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:56 INFO 140042773481280] #quality_metric: host=algo-1, epoch=52, train rmse <loss>=0.38744426044\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.8379230499268, \"sum\": 574.8379230499268, \"min\": 574.8379230499268}}, \"EndTime\": 1550845796.572083, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845795.996748}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:56 INFO 140042773481280] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 18339, \"sum\": 18339.0, \"min\": 18339}, \"Total Records Seen\": {\"count\": 1, \"max\": 1831780, \"sum\": 1831780.0, \"min\": 1831780}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 54, \"sum\": 54.0, \"min\": 54}}, \"EndTime\": 1550845796.57225, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 52}, \"StartTime\": 1550845795.997218}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:56 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60090.2404561 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:56.572] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 53, \"duration\": 573, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:56 INFO 140042773481280] #quality_metric: host=algo-1, epoch=53, batch=0 train rmse <loss>=0.374154816902\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:57 INFO 140042773481280] #quality_metric: host=algo-1, epoch=53, train rmse <loss>=0.381071987433\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.4161396026611, \"sum\": 571.4161396026611, \"min\": 571.4161396026611}}, \"EndTime\": 1550845797.14394, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845796.57213}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:57 INFO 140042773481280] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 18685, \"sum\": 18685.0, \"min\": 18685}, \"Total Records Seen\": {\"count\": 1, \"max\": 1866340, \"sum\": 1866340.0, \"min\": 1866340}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 55, \"sum\": 55.0, \"min\": 55}}, \"EndTime\": 1550845797.144145, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 53}, \"StartTime\": 1550845796.572493}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:57 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60444.2930395 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:57.144] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 570, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:57 INFO 140042773481280] #quality_metric: host=algo-1, epoch=54, batch=0 train rmse <loss>=0.367336317707\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:57 INFO 140042773481280] #quality_metric: host=algo-1, epoch=54, train rmse <loss>=0.374722299838\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 623.5659122467041, \"sum\": 623.5659122467041, \"min\": 623.5659122467041}}, \"EndTime\": 1550845797.767982, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845797.144006}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:57 INFO 140042773481280] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 19031, \"sum\": 19031.0, \"min\": 19031}, \"Total Records Seen\": {\"count\": 1, \"max\": 1900900, \"sum\": 1900900.0, \"min\": 1900900}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 56, \"sum\": 56.0, \"min\": 56}}, \"EndTime\": 1550845797.768202, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 54}, \"StartTime\": 1550845797.144384}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:57 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=55389.8574779 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:57.768] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 55, \"duration\": 622, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:57 INFO 140042773481280] #quality_metric: host=algo-1, epoch=55, batch=0 train rmse <loss>=0.3605558946\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:58 INFO 140042773481280] #quality_metric: host=algo-1, epoch=55, train rmse <loss>=0.368402206571\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 573.6169815063477, \"sum\": 573.6169815063477, \"min\": 573.6169815063477}}, \"EndTime\": 1550845798.342139, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845797.768048}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:58 INFO 140042773481280] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 19377, \"sum\": 19377.0, \"min\": 19377}, \"Total Records Seen\": {\"count\": 1, \"max\": 1935460, \"sum\": 1935460.0, \"min\": 1935460}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 57, \"sum\": 57.0, \"min\": 57}}, \"EndTime\": 1550845798.342381, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 55}, \"StartTime\": 1550845797.76849}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:58 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60206.3208121 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:58.342] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 572, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:58 INFO 140042773481280] #quality_metric: host=algo-1, epoch=56, batch=0 train rmse <loss>=0.353814038522\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:58 INFO 140042773481280] #quality_metric: host=algo-1, epoch=56, train rmse <loss>=0.362118955472\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 599.2100238800049, \"sum\": 599.2100238800049, \"min\": 599.2100238800049}}, \"EndTime\": 1550845798.941868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845798.342209}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:58 INFO 140042773481280] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 19723, \"sum\": 19723.0, \"min\": 19723}, \"Total Records Seen\": {\"count\": 1, \"max\": 1970020, \"sum\": 1970020.0, \"min\": 1970020}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 58, \"sum\": 58.0, \"min\": 58}}, \"EndTime\": 1550845798.942141, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 56}, \"StartTime\": 1550845798.342626}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:58 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57634.6827362 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:58.942] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 57, \"duration\": 598, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:58 INFO 140042773481280] #quality_metric: host=algo-1, epoch=57, batch=0 train rmse <loss>=0.347109246418\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:59 INFO 140042773481280] #quality_metric: host=algo-1, epoch=57, train rmse <loss>=0.355880299363\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 618.5219287872314, \"sum\": 618.5219287872314, \"min\": 618.5219287872314}}, \"EndTime\": 1550845799.561002, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845798.941988}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:59 INFO 140042773481280] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 20069, \"sum\": 20069.0, \"min\": 20069}, \"Total Records Seen\": {\"count\": 1, \"max\": 2004580, \"sum\": 2004580.0, \"min\": 2004580}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 59, \"sum\": 59.0, \"min\": 59}}, \"EndTime\": 1550845799.561223, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 57}, \"StartTime\": 1550845798.942447}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:59 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=55841.1103261 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:29:59.561] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 617, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:29:59 INFO 140042773481280] #quality_metric: host=algo-1, epoch=58, batch=0 train rmse <loss>=0.340437629331\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:00 INFO 140042773481280] #quality_metric: host=algo-1, epoch=58, train rmse <loss>=0.349694797207\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.2321014404297, \"sum\": 574.2321014404297, \"min\": 574.2321014404297}}, \"EndTime\": 1550845800.135768, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845799.561076}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:00 INFO 140042773481280] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 20415, \"sum\": 20415.0, \"min\": 20415}, \"Total Records Seen\": {\"count\": 1, \"max\": 2039140, \"sum\": 2039140.0, \"min\": 2039140}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 60, \"sum\": 60.0, \"min\": 60}}, \"EndTime\": 1550845800.135982, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 58}, \"StartTime\": 1550845799.561504}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:00 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60146.7146993 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:00.136] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 59, \"duration\": 573, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:00 INFO 140042773481280] #quality_metric: host=algo-1, epoch=59, batch=0 train rmse <loss>=0.333792862444\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/22/2019 14:30:00 INFO 140042773481280] #quality_metric: host=algo-1, epoch=59, train rmse <loss>=0.34357239303\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 575.6139755249023, \"sum\": 575.6139755249023, \"min\": 575.6139755249023}}, \"EndTime\": 1550845800.71201, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845800.135833}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:00 INFO 140042773481280] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 20761, \"sum\": 20761.0, \"min\": 20761}, \"Total Records Seen\": {\"count\": 1, \"max\": 2073700, \"sum\": 2073700.0, \"min\": 2073700}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 61, \"sum\": 61.0, \"min\": 61}}, \"EndTime\": 1550845800.712243, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 59}, \"StartTime\": 1550845800.136219}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:00 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59984.3852636 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:00.712] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 574, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:00 INFO 140042773481280] #quality_metric: host=algo-1, epoch=60, batch=0 train rmse <loss>=0.32716649612\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:01 INFO 140042773481280] #quality_metric: host=algo-1, epoch=60, train rmse <loss>=0.337525235819\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 566.8048858642578, \"sum\": 566.8048858642578, \"min\": 566.8048858642578}}, \"EndTime\": 1550845801.279358, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845800.712087}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:01 INFO 140042773481280] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 21107, \"sum\": 21107.0, \"min\": 21107}, \"Total Records Seen\": {\"count\": 1, \"max\": 2108260, \"sum\": 2108260.0, \"min\": 2108260}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 62, \"sum\": 62.0, \"min\": 62}}, \"EndTime\": 1550845801.279562, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 60}, \"StartTime\": 1550845800.712523}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:01 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60935.9403938 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:01.279] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 61, \"duration\": 565, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:01 INFO 140042773481280] #quality_metric: host=algo-1, epoch=61, batch=0 train rmse <loss>=0.32054847027\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:01 INFO 140042773481280] #quality_metric: host=algo-1, epoch=61, train rmse <loss>=0.331569239695\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 621.830940246582, \"sum\": 621.830940246582, \"min\": 621.830940246582}}, \"EndTime\": 1550845801.901658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845801.279423}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:01 INFO 140042773481280] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 21453, \"sum\": 21453.0, \"min\": 21453}, \"Total Records Seen\": {\"count\": 1, \"max\": 2142820, \"sum\": 2142820.0, \"min\": 2142820}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 63, \"sum\": 63.0, \"min\": 63}}, \"EndTime\": 1550845801.901865, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 61}, \"StartTime\": 1550845801.279797}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:01 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=55546.7979969 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:01.902] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 620, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:01 INFO 140042773481280] #quality_metric: host=algo-1, epoch=62, batch=0 train rmse <loss>=0.313927176249\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:02 INFO 140042773481280] #quality_metric: host=algo-1, epoch=62, train rmse <loss>=0.32572692485\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 594.5971012115479, \"sum\": 594.5971012115479, \"min\": 594.5971012115479}}, \"EndTime\": 1550845802.496951, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845801.901723}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:02 INFO 140042773481280] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 21799, \"sum\": 21799.0, \"min\": 21799}, \"Total Records Seen\": {\"count\": 1, \"max\": 2177380, \"sum\": 2177380.0, \"min\": 2177380}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 64, \"sum\": 64.0, \"min\": 64}}, \"EndTime\": 1550845802.497184, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 62}, \"StartTime\": 1550845801.902173}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:02 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58071.1628883 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:02.497] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 63, \"duration\": 593, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:02 INFO 140042773481280] #quality_metric: host=algo-1, epoch=63, batch=0 train rmse <loss>=0.307292161499\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:03 INFO 140042773481280] #quality_metric: host=algo-1, epoch=63, train rmse <loss>=0.320032897982\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 568.4669017791748, \"sum\": 568.4669017791748, \"min\": 568.4669017791748}}, \"EndTime\": 1550845803.065967, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845802.497027}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:03 INFO 140042773481280] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 22145, \"sum\": 22145.0, \"min\": 22145}, \"Total Records Seen\": {\"count\": 1, \"max\": 2211940, \"sum\": 2211940.0, \"min\": 2211940}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 65, \"sum\": 65.0, \"min\": 65}}, \"EndTime\": 1550845803.066185, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 63}, \"StartTime\": 1550845802.497468}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:03 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60752.8501861 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:03.066] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 567, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:03 INFO 140042773481280] #quality_metric: host=algo-1, epoch=64, batch=0 train rmse <loss>=0.300637791098\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:03 INFO 140042773481280] #quality_metric: host=algo-1, epoch=64, train rmse <loss>=0.314545580207\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 633.5089206695557, \"sum\": 633.5089206695557, \"min\": 633.5089206695557}}, \"EndTime\": 1550845803.700027, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845803.066033}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:03 INFO 140042773481280] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 22491, \"sum\": 22491.0, \"min\": 22491}, \"Total Records Seen\": {\"count\": 1, \"max\": 2246500, \"sum\": 2246500.0, \"min\": 2246500}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 66, \"sum\": 66.0, \"min\": 66}}, \"EndTime\": 1550845803.700267, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 64}, \"StartTime\": 1550845803.066487}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:03 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=54517.5756017 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:03.700] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 65, \"duration\": 632, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:03 INFO 140042773481280] #quality_metric: host=algo-1, epoch=65, batch=0 train rmse <loss>=0.29397588932\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:04 INFO 140042773481280] #quality_metric: host=algo-1, epoch=65, train rmse <loss>=0.309374329782\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.7931003570557, \"sum\": 574.7931003570557, \"min\": 574.7931003570557}}, \"EndTime\": 1550845804.275407, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845803.700093}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:04 INFO 140042773481280] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 22837, \"sum\": 22837.0, \"min\": 22837}, \"Total Records Seen\": {\"count\": 1, \"max\": 2281060, \"sum\": 2281060.0, \"min\": 2281060}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 67, \"sum\": 67.0, \"min\": 67}}, \"EndTime\": 1550845804.275675, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 65}, \"StartTime\": 1550845803.700582}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:04 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60080.9504515 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:04.275] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 573, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:04 INFO 140042773481280] #quality_metric: host=algo-1, epoch=66, batch=0 train rmse <loss>=0.287359369132\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:04 INFO 140042773481280] #quality_metric: host=algo-1, epoch=66, train rmse <loss>=0.304748041751\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 588.529109954834, \"sum\": 588.529109954834, \"min\": 588.529109954834}}, \"EndTime\": 1550845804.864514, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845804.275474}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:04 INFO 140042773481280] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 23183, \"sum\": 23183.0, \"min\": 23183}, \"Total Records Seen\": {\"count\": 1, \"max\": 2315620, \"sum\": 2315620.0, \"min\": 2315620}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}}, \"EndTime\": 1550845804.864758, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 66}, \"StartTime\": 1550845804.275953}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:04 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58680.5922663 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:04.864] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 67, \"duration\": 587, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:04 INFO 140042773481280] #quality_metric: host=algo-1, epoch=67, batch=0 train rmse <loss>=0.280917365145\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:05 INFO 140042773481280] #quality_metric: host=algo-1, epoch=67, train rmse <loss>=0.30119438047\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 596.2691307067871, \"sum\": 596.2691307067871, \"min\": 596.2691307067871}}, \"EndTime\": 1550845805.46137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845804.864581}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:05 INFO 140042773481280] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 23529, \"sum\": 23529.0, \"min\": 23529}, \"Total Records Seen\": {\"count\": 1, \"max\": 2350180, \"sum\": 2350180.0, \"min\": 2350180}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 69, \"sum\": 69.0, \"min\": 69}}, \"EndTime\": 1550845805.461574, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 67}, \"StartTime\": 1550845804.865071}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:05 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57925.0370895 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:05.461] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 594, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:05 INFO 140042773481280] #quality_metric: host=algo-1, epoch=68, batch=0 train rmse <loss>=0.274841791941\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:06 INFO 140042773481280] #quality_metric: host=algo-1, epoch=68, train rmse <loss>=0.29978456068\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 598.0510711669922, \"sum\": 598.0510711669922, \"min\": 598.0510711669922}}, \"EndTime\": 1550845806.059893, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845805.461435}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:06 INFO 140042773481280] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 23875, \"sum\": 23875.0, \"min\": 23875}, \"Total Records Seen\": {\"count\": 1, \"max\": 2384740, \"sum\": 2384740.0, \"min\": 2384740}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 70, \"sum\": 70.0, \"min\": 70}}, \"EndTime\": 1550845806.060073, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 68}, \"StartTime\": 1550845805.46181}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:06 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57756.2316303 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:06.060] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 69, \"duration\": 596, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:06 INFO 140042773481280] #quality_metric: host=algo-1, epoch=69, batch=0 train rmse <loss>=0.269828636749\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:06 INFO 140042773481280] #quality_metric: host=algo-1, epoch=69, train rmse <loss>=0.300832239907\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.30104637146, \"sum\": 580.30104637146, \"min\": 580.30104637146}}, \"EndTime\": 1550845806.64064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845806.059953}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:06 INFO 140042773481280] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 24221, \"sum\": 24221.0, \"min\": 24221}, \"Total Records Seen\": {\"count\": 1, \"max\": 2419300, \"sum\": 2419300.0, \"min\": 2419300}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 71, \"sum\": 71.0, \"min\": 71}}, \"EndTime\": 1550845806.640832, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 69}, \"StartTime\": 1550845806.060307}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:06 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59520.3255989 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:06.641] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 579, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:06 INFO 140042773481280] #quality_metric: host=algo-1, epoch=70, batch=0 train rmse <loss>=0.266035879655\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:07 INFO 140042773481280] #quality_metric: host=algo-1, epoch=70, train rmse <loss>=0.301514988601\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.4321136474609, \"sum\": 571.4321136474609, \"min\": 571.4321136474609}}, \"EndTime\": 1550845807.21257, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845806.640707}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:07 INFO 140042773481280] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 24567, \"sum\": 24567.0, \"min\": 24567}, \"Total Records Seen\": {\"count\": 1, \"max\": 2453860, \"sum\": 2453860.0, \"min\": 2453860}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}}, \"EndTime\": 1550845807.212747, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 70}, \"StartTime\": 1550845806.641112}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:07 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60444.923157 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:07.212] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 71, \"duration\": 570, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:07 INFO 140042773481280] #quality_metric: host=algo-1, epoch=71, batch=0 train rmse <loss>=0.258221176371\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:07 INFO 140042773481280] #quality_metric: host=algo-1, epoch=71, train rmse <loss>=0.298578052252\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 598.114013671875, \"sum\": 598.114013671875, \"min\": 598.114013671875}}, \"EndTime\": 1550845807.811167, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845807.212618}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:07 INFO 140042773481280] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 24913, \"sum\": 24913.0, \"min\": 24913}, \"Total Records Seen\": {\"count\": 1, \"max\": 2488420, \"sum\": 2488420.0, \"min\": 2488420}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 73, \"sum\": 73.0, \"min\": 73}}, \"EndTime\": 1550845807.811515, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 71}, \"StartTime\": 1550845807.213019}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:07 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57732.4924775 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:07.811] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 597, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:07 INFO 140042773481280] #quality_metric: host=algo-1, epoch=72, batch=0 train rmse <loss>=0.251479889947\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:08 INFO 140042773481280] #quality_metric: host=algo-1, epoch=72, train rmse <loss>=0.293735231951\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.2721157073975, \"sum\": 591.2721157073975, \"min\": 591.2721157073975}}, \"EndTime\": 1550845808.403138, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845807.811237}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:08 INFO 140042773481280] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 25259, \"sum\": 25259.0, \"min\": 25259}, \"Total Records Seen\": {\"count\": 1, \"max\": 2522980, \"sum\": 2522980.0, \"min\": 2522980}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 74, \"sum\": 74.0, \"min\": 74}}, \"EndTime\": 1550845808.403334, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 72}, \"StartTime\": 1550845807.811834}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:08 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58415.4779764 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:08.403] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 73, \"duration\": 589, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:08 INFO 140042773481280] #quality_metric: host=algo-1, epoch=73, batch=0 train rmse <loss>=0.24663908104\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:09 INFO 140042773481280] #quality_metric: host=algo-1, epoch=73, train rmse <loss>=0.288238564204\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 697.2169876098633, \"sum\": 697.2169876098633, \"min\": 697.2169876098633}}, \"EndTime\": 1550845809.100857, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845808.4032}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:09 INFO 140042773481280] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 25605, \"sum\": 25605.0, \"min\": 25605}, \"Total Records Seen\": {\"count\": 1, \"max\": 2557540, \"sum\": 2557540.0, \"min\": 2557540}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 75, \"sum\": 75.0, \"min\": 75}}, \"EndTime\": 1550845809.101081, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 73}, \"StartTime\": 1550845808.403604}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:09 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=49541.5802092 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:09.101] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 695, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:09 INFO 140042773481280] #quality_metric: host=algo-1, epoch=74, batch=0 train rmse <loss>=0.244269292267\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:09 INFO 140042773481280] #quality_metric: host=algo-1, epoch=74, train rmse <loss>=0.282585308084\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 593.5990810394287, \"sum\": 593.5990810394287, \"min\": 593.5990810394287}}, \"EndTime\": 1550845809.694963, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845809.100933}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:09 INFO 140042773481280] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 25951, \"sum\": 25951.0, \"min\": 25951}, \"Total Records Seen\": {\"count\": 1, \"max\": 2592100, \"sum\": 2592100.0, \"min\": 2592100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 76, \"sum\": 76.0, \"min\": 76}}, \"EndTime\": 1550845809.695149, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 74}, \"StartTime\": 1550845809.101331}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:09 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58187.6003756 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:09.695] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 75, \"duration\": 592, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:09 INFO 140042773481280] #quality_metric: host=algo-1, epoch=75, batch=0 train rmse <loss>=0.243684123992\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:10 INFO 140042773481280] #quality_metric: host=algo-1, epoch=75, train rmse <loss>=0.277022330774\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 604.3250560760498, \"sum\": 604.3250560760498, \"min\": 604.3250560760498}}, \"EndTime\": 1550845810.299827, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845809.695024}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:10 INFO 140042773481280] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 26297, \"sum\": 26297.0, \"min\": 26297}, \"Total Records Seen\": {\"count\": 1, \"max\": 2626660, \"sum\": 2626660.0, \"min\": 2626660}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 77, \"sum\": 77.0, \"min\": 77}}, \"EndTime\": 1550845810.300042, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 75}, \"StartTime\": 1550845809.69547}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:10 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57154.1013226 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:10.300] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 603, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:10 INFO 140042773481280] #quality_metric: host=algo-1, epoch=76, batch=0 train rmse <loss>=0.243800603064\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/22/2019 14:30:10 INFO 140042773481280] #quality_metric: host=algo-1, epoch=76, train rmse <loss>=0.271676683421\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 579.2219638824463, \"sum\": 579.2219638824463, \"min\": 579.2219638824463}}, \"EndTime\": 1550845810.879541, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845810.299893}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:10 INFO 140042773481280] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 26643, \"sum\": 26643.0, \"min\": 26643}, \"Total Records Seen\": {\"count\": 1, \"max\": 2661220, \"sum\": 2661220.0, \"min\": 2661220}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 78, \"sum\": 78.0, \"min\": 78}}, \"EndTime\": 1550845810.879743, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 76}, \"StartTime\": 1550845810.300289}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:10 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59631.2440335 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:10.879] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 77, \"duration\": 577, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:10 INFO 140042773481280] #quality_metric: host=algo-1, epoch=77, batch=0 train rmse <loss>=0.243786941077\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:11 INFO 140042773481280] #quality_metric: host=algo-1, epoch=77, train rmse <loss>=0.266631602475\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 573.9040374755859, \"sum\": 573.9040374755859, \"min\": 573.9040374755859}}, \"EndTime\": 1550845811.453906, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845810.879605}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:11 INFO 140042773481280] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 26989, \"sum\": 26989.0, \"min\": 26989}, \"Total Records Seen\": {\"count\": 1, \"max\": 2695780, \"sum\": 2695780.0, \"min\": 2695780}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 79, \"sum\": 79.0, \"min\": 79}}, \"EndTime\": 1550845811.45411, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 77}, \"StartTime\": 1550845810.879972}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:11 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60182.0244357 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:11.454] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 572, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:11 INFO 140042773481280] #quality_metric: host=algo-1, epoch=78, batch=0 train rmse <loss>=0.243130017697\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:12 INFO 140042773481280] #quality_metric: host=algo-1, epoch=78, train rmse <loss>=0.261958731538\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 599.5979309082031, \"sum\": 599.5979309082031, \"min\": 599.5979309082031}}, \"EndTime\": 1550845812.054017, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845811.453971}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:12 INFO 140042773481280] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 27335, \"sum\": 27335.0, \"min\": 27335}, \"Total Records Seen\": {\"count\": 1, \"max\": 2730340, \"sum\": 2730340.0, \"min\": 2730340}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 80, \"sum\": 80.0, \"min\": 80}}, \"EndTime\": 1550845812.054236, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 78}, \"StartTime\": 1550845811.454389}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:12 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57599.4140685 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:12.054] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 79, \"duration\": 598, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:12 INFO 140042773481280] #quality_metric: host=algo-1, epoch=79, batch=0 train rmse <loss>=0.241520106061\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:12 INFO 140042773481280] #quality_metric: host=algo-1, epoch=79, train rmse <loss>=0.257735470149\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.1171321868896, \"sum\": 578.1171321868896, \"min\": 578.1171321868896}}, \"EndTime\": 1550845812.632703, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845812.054084}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:12 INFO 140042773481280] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 27681, \"sum\": 27681.0, \"min\": 27681}, \"Total Records Seen\": {\"count\": 1, \"max\": 2764900, \"sum\": 2764900.0, \"min\": 2764900}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 81, \"sum\": 81.0, \"min\": 81}}, \"EndTime\": 1550845812.632903, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 79}, \"StartTime\": 1550845812.054553}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:12 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59742.2565492 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:12.633] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 577, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:12 INFO 140042773481280] #quality_metric: host=algo-1, epoch=80, batch=0 train rmse <loss>=0.238709741763\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:13 INFO 140042773481280] #quality_metric: host=algo-1, epoch=80, train rmse <loss>=0.254057832689\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.0869045257568, \"sum\": 574.0869045257568, \"min\": 574.0869045257568}}, \"EndTime\": 1550845813.207296, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845812.632769}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:13 INFO 140042773481280] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 28027, \"sum\": 28027.0, \"min\": 28027}, \"Total Records Seen\": {\"count\": 1, \"max\": 2799460, \"sum\": 2799460.0, \"min\": 2799460}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 82, \"sum\": 82.0, \"min\": 82}}, \"EndTime\": 1550845813.207504, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 80}, \"StartTime\": 1550845812.633178}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:13 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60162.8411625 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:13.207] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 81, \"duration\": 573, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:13 INFO 140042773481280] #quality_metric: host=algo-1, epoch=81, batch=0 train rmse <loss>=0.234385060412\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:13 INFO 140042773481280] #quality_metric: host=algo-1, epoch=81, train rmse <loss>=0.251052556066\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 586.1349105834961, \"sum\": 586.1349105834961, \"min\": 586.1349105834961}}, \"EndTime\": 1550845813.793911, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845813.207358}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:13 INFO 140042773481280] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 28373, \"sum\": 28373.0, \"min\": 28373}, \"Total Records Seen\": {\"count\": 1, \"max\": 2834020, \"sum\": 2834020.0, \"min\": 2834020}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 83, \"sum\": 83.0, \"min\": 83}}, \"EndTime\": 1550845813.794128, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 81}, \"StartTime\": 1550845813.207744}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:13 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58926.1257417 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:13.794] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 584, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:13 INFO 140042773481280] #quality_metric: host=algo-1, epoch=82, batch=0 train rmse <loss>=0.228088083285\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:14 INFO 140042773481280] #quality_metric: host=algo-1, epoch=82, train rmse <loss>=0.248885271832\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.5989875793457, \"sum\": 591.5989875793457, \"min\": 591.5989875793457}}, \"EndTime\": 1550845814.386049, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845813.793978}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:14 INFO 140042773481280] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 28719, \"sum\": 28719.0, \"min\": 28719}, \"Total Records Seen\": {\"count\": 1, \"max\": 2868580, \"sum\": 2868580.0, \"min\": 2868580}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 84, \"sum\": 84.0, \"min\": 84}}, \"EndTime\": 1550845814.386462, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 82}, \"StartTime\": 1550845813.794418}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:14 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58361.6191221 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:14.386] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 83, \"duration\": 590, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:14 INFO 140042773481280] #quality_metric: host=algo-1, epoch=83, batch=0 train rmse <loss>=0.219330893753\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:14 INFO 140042773481280] #quality_metric: host=algo-1, epoch=83, train rmse <loss>=0.247749557818\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 599.6599197387695, \"sum\": 599.6599197387695, \"min\": 599.6599197387695}}, \"EndTime\": 1550845814.98643, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845814.386114}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:14 INFO 140042773481280] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 29065, \"sum\": 29065.0, \"min\": 29065}, \"Total Records Seen\": {\"count\": 1, \"max\": 2903140, \"sum\": 2903140.0, \"min\": 2903140}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 85, \"sum\": 85.0, \"min\": 85}}, \"EndTime\": 1550845814.986623, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 83}, \"StartTime\": 1550845814.386738}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:14 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57598.4528003 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:14.986] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 598, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:14 INFO 140042773481280] #quality_metric: host=algo-1, epoch=84, batch=0 train rmse <loss>=0.208431932641\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:15 INFO 140042773481280] #quality_metric: host=algo-1, epoch=84, train rmse <loss>=0.247794150242\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 597.7270603179932, \"sum\": 597.7270603179932, \"min\": 597.7270603179932}}, \"EndTime\": 1550845815.58465, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845814.986494}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:15 INFO 140042773481280] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 29411, \"sum\": 29411.0, \"min\": 29411}, \"Total Records Seen\": {\"count\": 1, \"max\": 2937700, \"sum\": 2937700.0, \"min\": 2937700}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 86, \"sum\": 86.0, \"min\": 86}}, \"EndTime\": 1550845815.584877, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 84}, \"StartTime\": 1550845814.98689}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:15 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57781.7407571 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:15.585] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 85, \"duration\": 596, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:15 INFO 140042773481280] #quality_metric: host=algo-1, epoch=85, batch=0 train rmse <loss>=0.19922488334\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:16 INFO 140042773481280] #quality_metric: host=algo-1, epoch=85, train rmse <loss>=0.248922402042\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 579.0879726409912, \"sum\": 579.0879726409912, \"min\": 579.0879726409912}}, \"EndTime\": 1550845816.164276, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845815.584719}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:16 INFO 140042773481280] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 29757, \"sum\": 29757.0, \"min\": 29757}, \"Total Records Seen\": {\"count\": 1, \"max\": 2972260, \"sum\": 2972260.0, \"min\": 2972260}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 87, \"sum\": 87.0, \"min\": 87}}, \"EndTime\": 1550845816.164498, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 85}, \"StartTime\": 1550845815.585158}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:16 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59641.2052568 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:16.164] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 578, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:16 INFO 140042773481280] #quality_metric: host=algo-1, epoch=86, batch=0 train rmse <loss>=0.202700773479\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:16 INFO 140042773481280] #quality_metric: host=algo-1, epoch=86, train rmse <loss>=0.250511767526\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.4778594970703, \"sum\": 578.4778594970703, \"min\": 578.4778594970703}}, \"EndTime\": 1550845816.743334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845816.164344}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:16 INFO 140042773481280] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 30103, \"sum\": 30103.0, \"min\": 30103}, \"Total Records Seen\": {\"count\": 1, \"max\": 3006820, \"sum\": 3006820.0, \"min\": 3006820}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 88, \"sum\": 88.0, \"min\": 88}}, \"EndTime\": 1550845816.74354, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 86}, \"StartTime\": 1550845816.164824}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:16 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59706.9443528 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:16.743] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 87, \"duration\": 577, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:16 INFO 140042773481280] #quality_metric: host=algo-1, epoch=87, batch=0 train rmse <loss>=0.229313209381\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:17 INFO 140042773481280] #quality_metric: host=algo-1, epoch=87, train rmse <loss>=0.25147472338\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.9649791717529, \"sum\": 571.9649791717529, \"min\": 571.9649791717529}}, \"EndTime\": 1550845817.315788, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845816.743401}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:17 INFO 140042773481280] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 30449, \"sum\": 30449.0, \"min\": 30449}, \"Total Records Seen\": {\"count\": 1, \"max\": 3041380, \"sum\": 3041380.0, \"min\": 3041380}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 89, \"sum\": 89.0, \"min\": 89}}, \"EndTime\": 1550845817.315983, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 87}, \"StartTime\": 1550845816.74379}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:17 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60386.3280709 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:17.316] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 570, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:17 INFO 140042773481280] #quality_metric: host=algo-1, epoch=88, batch=0 train rmse <loss>=0.269409541418\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:17 INFO 140042773481280] #quality_metric: host=algo-1, epoch=88, train rmse <loss>=0.250957100404\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 579.7479152679443, \"sum\": 579.7479152679443, \"min\": 579.7479152679443}}, \"EndTime\": 1550845817.896022, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845817.315854}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:17 INFO 140042773481280] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 30795, \"sum\": 30795.0, \"min\": 30795}, \"Total Records Seen\": {\"count\": 1, \"max\": 3075940, \"sum\": 3075940.0, \"min\": 3075940}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 90, \"sum\": 90.0, \"min\": 90}}, \"EndTime\": 1550845817.896292, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 88}, \"StartTime\": 1550845817.316245}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:17 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59569.1718556 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:17.896] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 89, \"duration\": 578, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:17 INFO 140042773481280] #quality_metric: host=algo-1, epoch=89, batch=0 train rmse <loss>=0.302426427927\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:18 INFO 140042773481280] #quality_metric: host=algo-1, epoch=89, train rmse <loss>=0.248847151478\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 604.0430068969727, \"sum\": 604.0430068969727, \"min\": 604.0430068969727}}, \"EndTime\": 1550845818.500618, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845817.896086}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:18 INFO 140042773481280] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 31141, \"sum\": 31141.0, \"min\": 31141}, \"Total Records Seen\": {\"count\": 1, \"max\": 3110500, \"sum\": 3110500.0, \"min\": 3110500}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}}, \"EndTime\": 1550845818.500844, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 89}, \"StartTime\": 1550845817.896543}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:18 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57179.5323239 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:18.501] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 602, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:18 INFO 140042773481280] #quality_metric: host=algo-1, epoch=90, batch=0 train rmse <loss>=0.318971743776\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:19 INFO 140042773481280] #quality_metric: host=algo-1, epoch=90, train rmse <loss>=0.245508886018\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 607.1829795837402, \"sum\": 607.1829795837402, \"min\": 607.1829795837402}}, \"EndTime\": 1550845819.108469, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845818.500694}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:19 INFO 140042773481280] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 31487, \"sum\": 31487.0, \"min\": 31487}, \"Total Records Seen\": {\"count\": 1, \"max\": 3145060, \"sum\": 3145060.0, \"min\": 3145060}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 92, \"sum\": 92.0, \"min\": 92}}, \"EndTime\": 1550845819.108702, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 90}, \"StartTime\": 1550845818.501102}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:19 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56867.2778744 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:19.108] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 91, \"duration\": 606, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:19 INFO 140042773481280] #quality_metric: host=algo-1, epoch=91, batch=0 train rmse <loss>=0.320721130237\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:19 INFO 140042773481280] #quality_metric: host=algo-1, epoch=91, train rmse <loss>=0.24137855426\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 593.8971042633057, \"sum\": 593.8971042633057, \"min\": 593.8971042633057}}, \"EndTime\": 1550845819.702894, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845819.108537}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:19 INFO 140042773481280] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 31833, \"sum\": 31833.0, \"min\": 31833}, \"Total Records Seen\": {\"count\": 1, \"max\": 3179620, \"sum\": 3179620.0, \"min\": 3179620}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 93, \"sum\": 93.0, \"min\": 93}}, \"EndTime\": 1550845819.703105, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 91}, \"StartTime\": 1550845819.10897}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:19 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58158.6047566 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:19.703] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 592, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:19 INFO 140042773481280] #quality_metric: host=algo-1, epoch=92, batch=0 train rmse <loss>=0.312392178054\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:20 INFO 140042773481280] #quality_metric: host=algo-1, epoch=92, train rmse <loss>=0.236808006091\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.8481540679932, \"sum\": 571.8481540679932, \"min\": 571.8481540679932}}, \"EndTime\": 1550845820.27521, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845819.702966}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:20 INFO 140042773481280] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 32179, \"sum\": 32179.0, \"min\": 32179}, \"Total Records Seen\": {\"count\": 1, \"max\": 3214180, \"sum\": 3214180.0, \"min\": 3214180}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 94, \"sum\": 94.0, \"min\": 94}}, \"EndTime\": 1550845820.275426, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 92}, \"StartTime\": 1550845819.70333}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:20 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60396.5431821 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:20.275] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 93, \"duration\": 570, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:20 INFO 140042773481280] #quality_metric: host=algo-1, epoch=93, batch=0 train rmse <loss>=0.298045963071\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/22/2019 14:30:20 INFO 140042773481280] #quality_metric: host=algo-1, epoch=93, train rmse <loss>=0.23205343464\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 608.3459854125977, \"sum\": 608.3459854125977, \"min\": 608.3459854125977}}, \"EndTime\": 1550845820.884078, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845820.275276}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:20 INFO 140042773481280] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 32525, \"sum\": 32525.0, \"min\": 32525}, \"Total Records Seen\": {\"count\": 1, \"max\": 3248740, \"sum\": 3248740.0, \"min\": 3248740}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 95, \"sum\": 95.0, \"min\": 95}}, \"EndTime\": 1550845820.88428, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 93}, \"StartTime\": 1550845820.275701}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:20 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56777.4899796 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:20.884] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 607, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:20 INFO 140042773481280] #quality_metric: host=algo-1, epoch=94, batch=0 train rmse <loss>=0.280532005211\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:21 INFO 140042773481280] #quality_metric: host=algo-1, epoch=94, train rmse <loss>=0.227300545848\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 569.6840286254883, \"sum\": 569.6840286254883, \"min\": 569.6840286254883}}, \"EndTime\": 1550845821.454228, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845820.884142}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:21 INFO 140042773481280] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 32871, \"sum\": 32871.0, \"min\": 32871}, \"Total Records Seen\": {\"count\": 1, \"max\": 3283300, \"sum\": 3283300.0, \"min\": 3283300}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 96, \"sum\": 96.0, \"min\": 96}}, \"EndTime\": 1550845821.454619, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 94}, \"StartTime\": 1550845820.884514}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:21 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60607.6548325 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:21.454] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 95, \"duration\": 568, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:21 INFO 140042773481280] #quality_metric: host=algo-1, epoch=95, batch=0 train rmse <loss>=0.261760150425\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:22 INFO 140042773481280] #quality_metric: host=algo-1, epoch=95, train rmse <loss>=0.222688675483\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.8860836029053, \"sum\": 574.8860836029053, \"min\": 574.8860836029053}}, \"EndTime\": 1550845822.029794, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845821.454337}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:22 INFO 140042773481280] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 33217, \"sum\": 33217.0, \"min\": 33217}, \"Total Records Seen\": {\"count\": 1, \"max\": 3317860, \"sum\": 3317860.0, \"min\": 3317860}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 97, \"sum\": 97.0, \"min\": 97}}, \"EndTime\": 1550845822.030026, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 95}, \"StartTime\": 1550845821.454875}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:22 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60074.9744872 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:22.030] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 573, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:22 INFO 140042773481280] #quality_metric: host=algo-1, epoch=96, batch=0 train rmse <loss>=0.243015581628\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:22 INFO 140042773481280] #quality_metric: host=algo-1, epoch=96, train rmse <loss>=0.218328056854\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 600.139856338501, \"sum\": 600.139856338501, \"min\": 600.139856338501}}, \"EndTime\": 1550845822.63051, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845822.029863}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:22 INFO 140042773481280] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 33563, \"sum\": 33563.0, \"min\": 33563}, \"Total Records Seen\": {\"count\": 1, \"max\": 3352420, \"sum\": 3352420.0, \"min\": 3352420}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 98, \"sum\": 98.0, \"min\": 98}}, \"EndTime\": 1550845822.630733, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 96}, \"StartTime\": 1550845822.030339}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:22 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57550.8872487 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:22.630] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 97, \"duration\": 599, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:22 INFO 140042773481280] #quality_metric: host=algo-1, epoch=97, batch=0 train rmse <loss>=0.225187499017\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:23 INFO 140042773481280] #quality_metric: host=algo-1, epoch=97, train rmse <loss>=0.214311015672\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 581.8531513214111, \"sum\": 581.8531513214111, \"min\": 581.8531513214111}}, \"EndTime\": 1550845823.212876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845822.630579}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:23 INFO 140042773481280] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 33909, \"sum\": 33909.0, \"min\": 33909}, \"Total Records Seen\": {\"count\": 1, \"max\": 3386980, \"sum\": 3386980.0, \"min\": 3386980}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 99, \"sum\": 99.0, \"min\": 99}}, \"EndTime\": 1550845823.213095, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 97}, \"StartTime\": 1550845822.63099}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:23 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59358.5840604 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:23.213] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 580, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:23 INFO 140042773481280] #quality_metric: host=algo-1, epoch=98, batch=0 train rmse <loss>=0.208922646221\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:23 INFO 140042773481280] #quality_metric: host=algo-1, epoch=98, train rmse <loss>=0.210720316643\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.2800235748291, \"sum\": 574.2800235748291, \"min\": 574.2800235748291}}, \"EndTime\": 1550845823.787663, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845823.212943}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:23 INFO 140042773481280] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 34255, \"sum\": 34255.0, \"min\": 34255}, \"Total Records Seen\": {\"count\": 1, \"max\": 3421540, \"sum\": 3421540.0, \"min\": 3421540}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}}, \"EndTime\": 1550845823.787873, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 98}, \"StartTime\": 1550845823.213352}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:23 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60142.2227976 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:23.788] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 99, \"duration\": 573, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:23 INFO 140042773481280] #quality_metric: host=algo-1, epoch=99, batch=0 train rmse <loss>=0.194741884966\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:24 INFO 140042773481280] #quality_metric: host=algo-1, epoch=99, train rmse <loss>=0.207635523668\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 584.4368934631348, \"sum\": 584.4368934631348, \"min\": 584.4368934631348}}, \"EndTime\": 1550845824.372622, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845823.787734}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:24 INFO 140042773481280] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 34601, \"sum\": 34601.0, \"min\": 34601}, \"Total Records Seen\": {\"count\": 1, \"max\": 3456100, \"sum\": 3456100.0, \"min\": 3456100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 101, \"sum\": 101.0, \"min\": 101}}, \"EndTime\": 1550845824.372825, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 99}, \"StartTime\": 1550845823.788155}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:24 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59098.1386643 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:24.373] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 583, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:24 INFO 140042773481280] #quality_metric: host=algo-1, epoch=100, batch=0 train rmse <loss>=0.183137796625\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:24 INFO 140042773481280] #quality_metric: host=algo-1, epoch=100, train rmse <loss>=0.20513861611\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 620.2759742736816, \"sum\": 620.2759742736816, \"min\": 620.2759742736816}}, \"EndTime\": 1550845824.993382, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845824.372688}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:24 INFO 140042773481280] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 34947, \"sum\": 34947.0, \"min\": 34947}, \"Total Records Seen\": {\"count\": 1, \"max\": 3490660, \"sum\": 3490660.0, \"min\": 3490660}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 102, \"sum\": 102.0, \"min\": 102}}, \"EndTime\": 1550845824.993626, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 100}, \"StartTime\": 1550845824.373073}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:24 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=55681.7560623 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:24.993] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 101, \"duration\": 619, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:24 INFO 140042773481280] #quality_metric: host=algo-1, epoch=101, batch=0 train rmse <loss>=0.17466152701\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:25 INFO 140042773481280] #quality_metric: host=algo-1, epoch=101, train rmse <loss>=0.20331846281\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.084997177124, \"sum\": 574.084997177124, \"min\": 574.084997177124}}, \"EndTime\": 1550845825.568006, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845824.993454}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:25 INFO 140042773481280] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 35293, \"sum\": 35293.0, \"min\": 35293}, \"Total Records Seen\": {\"count\": 1, \"max\": 3525220, \"sum\": 3525220.0, \"min\": 3525220}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 103, \"sum\": 103.0, \"min\": 103}}, \"EndTime\": 1550845825.568161, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 101}, \"StartTime\": 1550845824.993896}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:25 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60169.1093503 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:25.568] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 102, \"duration\": 572, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:25 INFO 140042773481280] #quality_metric: host=algo-1, epoch=102, batch=0 train rmse <loss>=0.169956977112\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:26 INFO 140042773481280] #quality_metric: host=algo-1, epoch=102, train rmse <loss>=0.202271754875\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 582.4060440063477, \"sum\": 582.4060440063477, \"min\": 582.4060440063477}}, \"EndTime\": 1550845826.150853, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845825.568055}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:26 INFO 140042773481280] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 35639, \"sum\": 35639.0, \"min\": 35639}, \"Total Records Seen\": {\"count\": 1, \"max\": 3559780, \"sum\": 3559780.0, \"min\": 3559780}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 104, \"sum\": 104.0, \"min\": 104}}, \"EndTime\": 1550845826.151058, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 102}, \"StartTime\": 1550845825.568415}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:26 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59304.5984859 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:26.151] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 103, \"duration\": 581, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:26 INFO 140042773481280] #quality_metric: host=algo-1, epoch=103, batch=0 train rmse <loss>=0.169654899543\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:26 INFO 140042773481280] #quality_metric: host=algo-1, epoch=103, train rmse <loss>=0.202097224275\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 623.2759952545166, \"sum\": 623.2759952545166, \"min\": 623.2759952545166}}, \"EndTime\": 1550845826.774611, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845826.150918}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:26 INFO 140042773481280] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 35985, \"sum\": 35985.0, \"min\": 35985}, \"Total Records Seen\": {\"count\": 1, \"max\": 3594340, \"sum\": 3594340.0, \"min\": 3594340}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 105, \"sum\": 105.0, \"min\": 105}}, \"EndTime\": 1550845826.774942, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 103}, \"StartTime\": 1550845826.151303}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:26 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=55405.8419803 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:26.775] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 104, \"duration\": 622, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:26 INFO 140042773481280] #quality_metric: host=algo-1, epoch=104, batch=0 train rmse <loss>=0.174011339651\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:27 INFO 140042773481280] #quality_metric: host=algo-1, epoch=104, train rmse <loss>=0.202878710993\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 568.7150955200195, \"sum\": 568.7150955200195, \"min\": 568.7150955200195}}, \"EndTime\": 1550845827.343936, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845826.774682}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:27 INFO 140042773481280] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 36331, \"sum\": 36331.0, \"min\": 36331}, \"Total Records Seen\": {\"count\": 1, \"max\": 3628900, \"sum\": 3628900.0, \"min\": 3628900}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 106, \"sum\": 106.0, \"min\": 106}}, \"EndTime\": 1550845827.344142, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 104}, \"StartTime\": 1550845826.775191}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:27 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60731.5201697 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:27.344] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 105, \"duration\": 567, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:27 INFO 140042773481280] #quality_metric: host=algo-1, epoch=105, batch=0 train rmse <loss>=0.182276554753\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:27 INFO 140042773481280] #quality_metric: host=algo-1, epoch=105, train rmse <loss>=0.204654614198\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 577.3332118988037, \"sum\": 577.3332118988037, \"min\": 577.3332118988037}}, \"EndTime\": 1550845827.921736, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845827.344001}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:27 INFO 140042773481280] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 36677, \"sum\": 36677.0, \"min\": 36677}, \"Total Records Seen\": {\"count\": 1, \"max\": 3663460, \"sum\": 3663460.0, \"min\": 3663460}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 107, \"sum\": 107.0, \"min\": 107}}, \"EndTime\": 1550845827.921954, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 105}, \"StartTime\": 1550845827.344373}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:27 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59822.2877839 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:27.922] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 106, \"duration\": 576, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:27 INFO 140042773481280] #quality_metric: host=algo-1, epoch=106, batch=0 train rmse <loss>=0.192103173589\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:28 INFO 140042773481280] #quality_metric: host=algo-1, epoch=106, train rmse <loss>=0.207379160734\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 568.5150623321533, \"sum\": 568.5150623321533, \"min\": 568.5150623321533}}, \"EndTime\": 1550845828.490778, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845827.921803}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:28 INFO 140042773481280] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 37023, \"sum\": 37023.0, \"min\": 37023}, \"Total Records Seen\": {\"count\": 1, \"max\": 3698020, \"sum\": 3698020.0, \"min\": 3698020}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 108, \"sum\": 108.0, \"min\": 108}}, \"EndTime\": 1550845828.490993, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 106}, \"StartTime\": 1550845827.922233}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:28 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60744.3214729 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:28.491] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 107, \"duration\": 567, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:28 INFO 140042773481280] #quality_metric: host=algo-1, epoch=107, batch=0 train rmse <loss>=0.19966619769\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:29 INFO 140042773481280] #quality_metric: host=algo-1, epoch=107, train rmse <loss>=0.210895068205\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 614.3841743469238, \"sum\": 614.3841743469238, \"min\": 614.3841743469238}}, \"EndTime\": 1550845829.105748, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845828.490844}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:29 INFO 140042773481280] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 37369, \"sum\": 37369.0, \"min\": 37369}, \"Total Records Seen\": {\"count\": 1, \"max\": 3732580, \"sum\": 3732580.0, \"min\": 3732580}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 109, \"sum\": 109.0, \"min\": 109}}, \"EndTime\": 1550845829.105976, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 107}, \"StartTime\": 1550845828.491332}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:29 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56215.6721325 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:29.106] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 108, \"duration\": 613, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:29 INFO 140042773481280] #quality_metric: host=algo-1, epoch=108, batch=0 train rmse <loss>=0.201124617572\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:29 INFO 140042773481280] #quality_metric: host=algo-1, epoch=108, train rmse <loss>=0.214943369158\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 589.5729064941406, \"sum\": 589.5729064941406, \"min\": 589.5729064941406}}, \"EndTime\": 1550845829.695881, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845829.10582}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:29 INFO 140042773481280] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 37715, \"sum\": 37715.0, \"min\": 37715}, \"Total Records Seen\": {\"count\": 1, \"max\": 3767140, \"sum\": 3767140.0, \"min\": 3767140}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 110, \"sum\": 110.0, \"min\": 110}}, \"EndTime\": 1550845829.696119, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 108}, \"StartTime\": 1550845829.106276}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:29 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58577.8656834 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:29.696] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 109, \"duration\": 588, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:29 INFO 140042773481280] #quality_metric: host=algo-1, epoch=109, batch=0 train rmse <loss>=0.194982295333\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:30 INFO 140042773481280] #quality_metric: host=algo-1, epoch=109, train rmse <loss>=0.219224922322\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 579.8640251159668, \"sum\": 579.8640251159668, \"min\": 579.8640251159668}}, \"EndTime\": 1550845830.276278, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845829.695957}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:30 INFO 140042773481280] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 38061, \"sum\": 38061.0, \"min\": 38061}, \"Total Records Seen\": {\"count\": 1, \"max\": 3801700, \"sum\": 3801700.0, \"min\": 3801700}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 111, \"sum\": 111.0, \"min\": 111}}, \"EndTime\": 1550845830.276627, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 109}, \"StartTime\": 1550845829.696382}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:30 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59545.1422994 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:30.276] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 110, \"duration\": 578, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:30 INFO 140042773481280] #quality_metric: host=algo-1, epoch=110, batch=0 train rmse <loss>=0.183323424967\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/22/2019 14:30:30 INFO 140042773481280] #quality_metric: host=algo-1, epoch=110, train rmse <loss>=0.223481784641\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 608.0150604248047, \"sum\": 608.0150604248047, \"min\": 608.0150604248047}}, \"EndTime\": 1550845830.885026, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845830.276345}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:30 INFO 140042773481280] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 38407, \"sum\": 38407.0, \"min\": 38407}, \"Total Records Seen\": {\"count\": 1, \"max\": 3836260, \"sum\": 3836260.0, \"min\": 3836260}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 112, \"sum\": 112.0, \"min\": 112}}, \"EndTime\": 1550845830.885417, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 110}, \"StartTime\": 1550845830.276977}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:30 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56784.0290511 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:30.885] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 111, \"duration\": 607, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:30 INFO 140042773481280] #quality_metric: host=algo-1, epoch=111, batch=0 train rmse <loss>=0.170364826808\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:31 INFO 140042773481280] #quality_metric: host=algo-1, epoch=111, train rmse <loss>=0.22753172901\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.5479850769043, \"sum\": 571.5479850769043, \"min\": 571.5479850769043}}, \"EndTime\": 1550845831.459012, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845830.885097}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:31 INFO 140042773481280] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 38753, \"sum\": 38753.0, \"min\": 38753}, \"Total Records Seen\": {\"count\": 1, \"max\": 3870820, \"sum\": 3870820.0, \"min\": 3870820}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 113, \"sum\": 113.0, \"min\": 113}}, \"EndTime\": 1550845831.459219, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 111}, \"StartTime\": 1550845830.887431}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:31 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60259.7567829 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:31.459] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 112, \"duration\": 569, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:31 INFO 140042773481280] #quality_metric: host=algo-1, epoch=112, batch=0 train rmse <loss>=0.159641947361\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:32 INFO 140042773481280] #quality_metric: host=algo-1, epoch=112, train rmse <loss>=0.231235328758\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.281909942627, \"sum\": 571.281909942627, \"min\": 571.281909942627}}, \"EndTime\": 1550845832.030783, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845831.459077}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:32 INFO 140042773481280] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 39099, \"sum\": 39099.0, \"min\": 39099}, \"Total Records Seen\": {\"count\": 1, \"max\": 3905380, \"sum\": 3905380.0, \"min\": 3905380}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 114, \"sum\": 114.0, \"min\": 114}}, \"EndTime\": 1550845832.031046, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 112}, \"StartTime\": 1550845831.459468}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:32 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60452.1326355 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:32.031] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 113, \"duration\": 570, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:32 INFO 140042773481280] #quality_metric: host=algo-1, epoch=113, batch=0 train rmse <loss>=0.152553964979\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:32 INFO 140042773481280] #quality_metric: host=algo-1, epoch=113, train rmse <loss>=0.23445135042\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.2911777496338, \"sum\": 578.2911777496338, \"min\": 578.2911777496338}}, \"EndTime\": 1550845832.609613, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845832.030876}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:32 INFO 140042773481280] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 39445, \"sum\": 39445.0, \"min\": 39445}, \"Total Records Seen\": {\"count\": 1, \"max\": 3939940, \"sum\": 3939940.0, \"min\": 3939940}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 115, \"sum\": 115.0, \"min\": 115}}, \"EndTime\": 1550845832.609802, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 113}, \"StartTime\": 1550845832.031295}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:32 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59728.0036062 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:32.609] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 114, \"duration\": 577, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:32 INFO 140042773481280] #quality_metric: host=algo-1, epoch=114, batch=0 train rmse <loss>=0.148864181036\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:33 INFO 140042773481280] #quality_metric: host=algo-1, epoch=114, train rmse <loss>=0.237033649288\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 607.1970462799072, \"sum\": 607.1970462799072, \"min\": 607.1970462799072}}, \"EndTime\": 1550845833.21727, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845832.609672}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:33 INFO 140042773481280] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 39791, \"sum\": 39791.0, \"min\": 39791}, \"Total Records Seen\": {\"count\": 1, \"max\": 3974500, \"sum\": 3974500.0, \"min\": 3974500}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 116, \"sum\": 116.0, \"min\": 116}}, \"EndTime\": 1550845833.217465, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 114}, \"StartTime\": 1550845832.610043}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:33 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56884.5953744 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:33.217] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 115, \"duration\": 606, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:33 INFO 140042773481280] #quality_metric: host=algo-1, epoch=115, batch=0 train rmse <loss>=0.147657622477\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:33 INFO 140042773481280] #quality_metric: host=algo-1, epoch=115, train rmse <loss>=0.238864472099\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.2738246917725, \"sum\": 574.2738246917725, \"min\": 574.2738246917725}}, \"EndTime\": 1550845833.792045, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845833.217335}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:33 INFO 140042773481280] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 40137, \"sum\": 40137.0, \"min\": 40137}, \"Total Records Seen\": {\"count\": 1, \"max\": 4009060, \"sum\": 4009060.0, \"min\": 4009060}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 117, \"sum\": 117.0, \"min\": 117}}, \"EndTime\": 1550845833.792261, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 115}, \"StartTime\": 1550845833.21774}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:33 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60141.0500225 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:33.792] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 116, \"duration\": 573, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:33 INFO 140042773481280] #quality_metric: host=algo-1, epoch=116, batch=0 train rmse <loss>=0.147786812355\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:34 INFO 140042773481280] #quality_metric: host=algo-1, epoch=116, train rmse <loss>=0.239888572767\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 597.9499816894531, \"sum\": 597.9499816894531, \"min\": 597.9499816894531}}, \"EndTime\": 1550845834.390514, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845833.792112}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:34 INFO 140042773481280] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 40483, \"sum\": 40483.0, \"min\": 40483}, \"Total Records Seen\": {\"count\": 1, \"max\": 4043620, \"sum\": 4043620.0, \"min\": 4043620}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 118, \"sum\": 118.0, \"min\": 118}}, \"EndTime\": 1550845834.390678, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 116}, \"StartTime\": 1550845833.792537}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:34 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57767.924354 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:34.390] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 117, \"duration\": 596, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:34 INFO 140042773481280] #quality_metric: host=algo-1, epoch=117, batch=0 train rmse <loss>=0.148076455576\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:34 INFO 140042773481280] #quality_metric: host=algo-1, epoch=117, train rmse <loss>=0.24012450912\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 582.0469856262207, \"sum\": 582.0469856262207, \"min\": 582.0469856262207}}, \"EndTime\": 1550845834.973008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845834.390564}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:34 INFO 140042773481280] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 40829, \"sum\": 40829.0, \"min\": 40829}, \"Total Records Seen\": {\"count\": 1, \"max\": 4078180, \"sum\": 4078180.0, \"min\": 4078180}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 119, \"sum\": 119.0, \"min\": 119}}, \"EndTime\": 1550845834.973232, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 117}, \"StartTime\": 1550845834.39093}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:34 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59340.553659 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:34.973] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 118, \"duration\": 581, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:34 INFO 140042773481280] #quality_metric: host=algo-1, epoch=118, batch=0 train rmse <loss>=0.1475717131\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:35 INFO 140042773481280] #quality_metric: host=algo-1, epoch=118, train rmse <loss>=0.239654052897\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 602.226972579956, \"sum\": 602.226972579956, \"min\": 602.226972579956}}, \"EndTime\": 1550845835.575698, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845834.973077}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:35 INFO 140042773481280] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 41175, \"sum\": 41175.0, \"min\": 41175}, \"Total Records Seen\": {\"count\": 1, \"max\": 4112740, \"sum\": 4112740.0, \"min\": 4112740}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 120, \"sum\": 120.0, \"min\": 120}}, \"EndTime\": 1550845835.575903, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 118}, \"StartTime\": 1550845834.973441}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:35 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57355.0076682 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:35.576] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 119, \"duration\": 601, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:35 INFO 140042773481280] #quality_metric: host=algo-1, epoch=119, batch=0 train rmse <loss>=0.14572546739\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:36 INFO 140042773481280] #quality_metric: host=algo-1, epoch=119, train rmse <loss>=0.238600006533\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.3629417419434, \"sum\": 578.3629417419434, \"min\": 578.3629417419434}}, \"EndTime\": 1550845836.15453, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845835.575763}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:36 INFO 140042773481280] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 41521, \"sum\": 41521.0, \"min\": 41521}, \"Total Records Seen\": {\"count\": 1, \"max\": 4147300, \"sum\": 4147300.0, \"min\": 4147300}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 121, \"sum\": 121.0, \"min\": 121}}, \"EndTime\": 1550845836.154747, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 119}, \"StartTime\": 1550845835.576135}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:36 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59717.7919497 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:36.154] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 120, \"duration\": 577, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:36 INFO 140042773481280] #quality_metric: host=algo-1, epoch=120, batch=0 train rmse <loss>=0.142425907348\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:36 INFO 140042773481280] #quality_metric: host=algo-1, epoch=120, train rmse <loss>=0.237103921947\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 573.9860534667969, \"sum\": 573.9860534667969, \"min\": 573.9860534667969}}, \"EndTime\": 1550845836.728991, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845836.154601}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:36 INFO 140042773481280] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 41867, \"sum\": 41867.0, \"min\": 41867}, \"Total Records Seen\": {\"count\": 1, \"max\": 4181860, \"sum\": 4181860.0, \"min\": 4181860}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 122, \"sum\": 122.0, \"min\": 122}}, \"EndTime\": 1550845836.729153, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 120}, \"StartTime\": 1550845836.154979}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:36 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60179.0762103 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:36.729] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 121, \"duration\": 572, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:36 INFO 140042773481280] #quality_metric: host=algo-1, epoch=121, batch=0 train rmse <loss>=0.137904054674\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:37 INFO 140042773481280] #quality_metric: host=algo-1, epoch=121, train rmse <loss>=0.235309502159\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 609.6630096435547, \"sum\": 609.6630096435547, \"min\": 609.6630096435547}}, \"EndTime\": 1550845837.339128, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845836.729039}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:37 INFO 140042773481280] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 42213, \"sum\": 42213.0, \"min\": 42213}, \"Total Records Seen\": {\"count\": 1, \"max\": 4216420, \"sum\": 4216420.0, \"min\": 4216420}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 123, \"sum\": 123.0, \"min\": 123}}, \"EndTime\": 1550845837.339322, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 121}, \"StartTime\": 1550845836.729432}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:37 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56653.8652784 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:37.339] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 122, \"duration\": 608, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:37 INFO 140042773481280] #quality_metric: host=algo-1, epoch=122, batch=0 train rmse <loss>=0.13260897132\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:37 INFO 140042773481280] #quality_metric: host=algo-1, epoch=122, train rmse <loss>=0.233353804387\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.141939163208, \"sum\": 591.141939163208, \"min\": 591.141939163208}}, \"EndTime\": 1550845837.93077, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845837.339193}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:37 INFO 140042773481280] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 42559, \"sum\": 42559.0, \"min\": 42559}, \"Total Records Seen\": {\"count\": 1, \"max\": 4250980, \"sum\": 4250980.0, \"min\": 4250980}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 124, \"sum\": 124.0, \"min\": 124}}, \"EndTime\": 1550845837.930975, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 122}, \"StartTime\": 1550845837.339598}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:37 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58428.5225223 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:37.931] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 123, \"duration\": 589, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:37 INFO 140042773481280] #quality_metric: host=algo-1, epoch=123, batch=0 train rmse <loss>=0.127112838051\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:38 INFO 140042773481280] #quality_metric: host=algo-1, epoch=123, train rmse <loss>=0.231362630708\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 568.3550834655762, \"sum\": 568.3550834655762, \"min\": 568.3550834655762}}, \"EndTime\": 1550845838.499589, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845837.930834}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:38 INFO 140042773481280] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 42905, \"sum\": 42905.0, \"min\": 42905}, \"Total Records Seen\": {\"count\": 1, \"max\": 4285540, \"sum\": 4285540.0, \"min\": 4285540}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 125, \"sum\": 125.0, \"min\": 125}}, \"EndTime\": 1550845838.49979, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 123}, \"StartTime\": 1550845837.931204}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:38 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60770.6026788 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:38.499] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 124, \"duration\": 567, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:38 INFO 140042773481280] #quality_metric: host=algo-1, epoch=124, batch=0 train rmse <loss>=0.12204683368\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:39 INFO 140042773481280] #quality_metric: host=algo-1, epoch=124, train rmse <loss>=0.229449392001\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 567.6999092102051, \"sum\": 567.6999092102051, \"min\": 567.6999092102051}}, \"EndTime\": 1550845839.067751, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845838.499652}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:39 INFO 140042773481280] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 43251, \"sum\": 43251.0, \"min\": 43251}, \"Total Records Seen\": {\"count\": 1, \"max\": 4320100, \"sum\": 4320100.0, \"min\": 4320100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 126, \"sum\": 126.0, \"min\": 126}}, \"EndTime\": 1550845839.067952, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 124}, \"StartTime\": 1550845838.500023}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:39 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60840.5673774 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:39.068] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 125, \"duration\": 566, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:39 INFO 140042773481280] #quality_metric: host=algo-1, epoch=125, batch=0 train rmse <loss>=0.11806637596\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:39 INFO 140042773481280] #quality_metric: host=algo-1, epoch=125, train rmse <loss>=0.227715646744\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 632.6661109924316, \"sum\": 632.6661109924316, \"min\": 632.6661109924316}}, \"EndTime\": 1550845839.700882, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845839.067815}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:39 INFO 140042773481280] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 43597, \"sum\": 43597.0, \"min\": 43597}, \"Total Records Seen\": {\"count\": 1, \"max\": 4354660, \"sum\": 4354660.0, \"min\": 4354660}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 127, \"sum\": 127.0, \"min\": 127}}, \"EndTime\": 1550845839.701098, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 125}, \"StartTime\": 1550845839.068187}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:39 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=54595.1706514 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:39.701] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 126, \"duration\": 631, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:39 INFO 140042773481280] #quality_metric: host=algo-1, epoch=126, batch=0 train rmse <loss>=0.115817188652\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:40 INFO 140042773481280] #quality_metric: host=algo-1, epoch=126, train rmse <loss>=0.226252581405\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 583.6191177368164, \"sum\": 583.6191177368164, \"min\": 583.6191177368164}}, \"EndTime\": 1550845840.284997, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845839.700953}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:40 INFO 140042773481280] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 43943, \"sum\": 43943.0, \"min\": 43943}, \"Total Records Seen\": {\"count\": 1, \"max\": 4389220, \"sum\": 4389220.0, \"min\": 4389220}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 128, \"sum\": 128.0, \"min\": 128}}, \"EndTime\": 1550845840.285193, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 126}, \"StartTime\": 1550845839.701345}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:40 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59180.7044846 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:40.285] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 127, \"duration\": 582, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:40 INFO 140042773481280] #quality_metric: host=algo-1, epoch=127, batch=0 train rmse <loss>=0.115888393521\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/22/2019 14:30:40 INFO 140042773481280] #quality_metric: host=algo-1, epoch=127, train rmse <loss>=0.225142132804\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 579.7219276428223, \"sum\": 579.7219276428223, \"min\": 579.7219276428223}}, \"EndTime\": 1550845840.865238, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845840.285062}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:40 INFO 140042773481280] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 44289, \"sum\": 44289.0, \"min\": 44289}, \"Total Records Seen\": {\"count\": 1, \"max\": 4423780, \"sum\": 4423780.0, \"min\": 4423780}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 129, \"sum\": 129.0, \"min\": 129}}, \"EndTime\": 1550845840.865589, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 127}, \"StartTime\": 1550845840.285486}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:40 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59562.8077638 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:40.865] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 128, \"duration\": 578, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:40 INFO 140042773481280] #quality_metric: host=algo-1, epoch=128, batch=0 train rmse <loss>=0.11875679599\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:41 INFO 140042773481280] #quality_metric: host=algo-1, epoch=128, train rmse <loss>=0.224457690256\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 607.0458889007568, \"sum\": 607.0458889007568, \"min\": 607.0458889007568}}, \"EndTime\": 1550845841.472939, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845840.865353}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:41 INFO 140042773481280] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 44635, \"sum\": 44635.0, \"min\": 44635}, \"Total Records Seen\": {\"count\": 1, \"max\": 4458340, \"sum\": 4458340.0, \"min\": 4458340}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 130, \"sum\": 130.0, \"min\": 130}}, \"EndTime\": 1550845841.473274, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 128}, \"StartTime\": 1550845840.865862}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:41 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56885.0418411 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:41.473] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 129, \"duration\": 606, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:41 INFO 140042773481280] #quality_metric: host=algo-1, epoch=129, batch=0 train rmse <loss>=0.124737764901\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:42 INFO 140042773481280] #quality_metric: host=algo-1, epoch=129, train rmse <loss>=0.224265004645\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 581.0739994049072, \"sum\": 581.0739994049072, \"min\": 581.0739994049072}}, \"EndTime\": 1550845842.054619, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845841.47304}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:42 INFO 140042773481280] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 44981, \"sum\": 44981.0, \"min\": 44981}, \"Total Records Seen\": {\"count\": 1, \"max\": 4492900, \"sum\": 4492900.0, \"min\": 4492900}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 131, \"sum\": 131.0, \"min\": 131}}, \"EndTime\": 1550845842.054886, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 129}, \"StartTime\": 1550845841.473516}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:42 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59430.985933 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:42.055] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 130, \"duration\": 579, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:42 INFO 140042773481280] #quality_metric: host=algo-1, epoch=130, batch=0 train rmse <loss>=0.133972056187\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:42 INFO 140042773481280] #quality_metric: host=algo-1, epoch=130, train rmse <loss>=0.224621212768\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 573.5201835632324, \"sum\": 573.5201835632324, \"min\": 573.5201835632324}}, \"EndTime\": 1550845842.628742, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845842.054716}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:42 INFO 140042773481280] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 45327, \"sum\": 45327.0, \"min\": 45327}, \"Total Records Seen\": {\"count\": 1, \"max\": 4527460, \"sum\": 4527460.0, \"min\": 4527460}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 132, \"sum\": 132.0, \"min\": 132}}, \"EndTime\": 1550845842.628946, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 130}, \"StartTime\": 1550845842.055191}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:42 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60222.9045978 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:42.629] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 131, \"duration\": 572, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:42 INFO 140042773481280] #quality_metric: host=algo-1, epoch=131, batch=0 train rmse <loss>=0.146448604031\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:43 INFO 140042773481280] #quality_metric: host=algo-1, epoch=131, train rmse <loss>=0.225573392285\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.6490440368652, \"sum\": 578.6490440368652, \"min\": 578.6490440368652}}, \"EndTime\": 1550845843.207859, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845842.628806}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:43 INFO 140042773481280] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 45673, \"sum\": 45673.0, \"min\": 45673}, \"Total Records Seen\": {\"count\": 1, \"max\": 4562020, \"sum\": 4562020.0, \"min\": 4562020}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 133, \"sum\": 133.0, \"min\": 133}}, \"EndTime\": 1550845843.208072, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 131}, \"StartTime\": 1550845842.629179}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:43 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59688.6034186 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:43.208] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 132, \"duration\": 577, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:43 INFO 140042773481280] #quality_metric: host=algo-1, epoch=132, batch=0 train rmse <loss>=0.16203589555\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:43 INFO 140042773481280] #quality_metric: host=algo-1, epoch=132, train rmse <loss>=0.227155387822\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 603.6348342895508, \"sum\": 603.6348342895508, \"min\": 603.6348342895508}}, \"EndTime\": 1550845843.811975, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845843.207923}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:43 INFO 140042773481280] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 46019, \"sum\": 46019.0, \"min\": 46019}, \"Total Records Seen\": {\"count\": 1, \"max\": 4596580, \"sum\": 4596580.0, \"min\": 4596580}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 134, \"sum\": 134.0, \"min\": 134}}, \"EndTime\": 1550845843.812263, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 132}, \"StartTime\": 1550845843.208308}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:43 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57209.9078122 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:43.812] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 133, \"duration\": 602, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:43 INFO 140042773481280] #quality_metric: host=algo-1, epoch=133, batch=0 train rmse <loss>=0.180482977765\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:44 INFO 140042773481280] #quality_metric: host=algo-1, epoch=133, train rmse <loss>=0.229382387925\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 610.5442047119141, \"sum\": 610.5442047119141, \"min\": 610.5442047119141}}, \"EndTime\": 1550845844.423267, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845843.812064}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:44 INFO 140042773481280] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 46365, \"sum\": 46365.0, \"min\": 46365}, \"Total Records Seen\": {\"count\": 1, \"max\": 4631140, \"sum\": 4631140.0, \"min\": 4631140}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 135, \"sum\": 135.0, \"min\": 135}}, \"EndTime\": 1550845844.423486, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 133}, \"StartTime\": 1550845843.812531}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:44 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56556.5175376 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:44.423] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 134, \"duration\": 609, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:44 INFO 140042773481280] #quality_metric: host=algo-1, epoch=134, batch=0 train rmse <loss>=0.201377949765\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:45 INFO 140042773481280] #quality_metric: host=algo-1, epoch=134, train rmse <loss>=0.232244855066\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.1478996276855, \"sum\": 591.1478996276855, \"min\": 591.1478996276855}}, \"EndTime\": 1550845845.014903, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845844.42334}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:45 INFO 140042773481280] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 46711, \"sum\": 46711.0, \"min\": 46711}, \"Total Records Seen\": {\"count\": 1, \"max\": 4665700, \"sum\": 4665700.0, \"min\": 4665700}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 136, \"sum\": 136.0, \"min\": 136}}, \"EndTime\": 1550845845.015192, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 134}, \"StartTime\": 1550845844.423724}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:45 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58417.7379859 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:45.015] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 135, \"duration\": 590, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:45 INFO 140042773481280] #quality_metric: host=algo-1, epoch=135, batch=0 train rmse <loss>=0.224066897553\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:45 INFO 140042773481280] #quality_metric: host=algo-1, epoch=135, train rmse <loss>=0.235703227561\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 604.8111915588379, \"sum\": 604.8111915588379, \"min\": 604.8111915588379}}, \"EndTime\": 1550845845.620352, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845845.014999}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:45 INFO 140042773481280] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 47057, \"sum\": 47057.0, \"min\": 47057}, \"Total Records Seen\": {\"count\": 1, \"max\": 4700260, \"sum\": 4700260.0, \"min\": 4700260}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 137, \"sum\": 137.0, \"min\": 137}}, \"EndTime\": 1550845845.620564, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 135}, \"StartTime\": 1550845845.015475}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:45 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57103.9594901 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:45.620] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 136, \"duration\": 603, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:45 INFO 140042773481280] #quality_metric: host=algo-1, epoch=136, batch=0 train rmse <loss>=0.247560163564\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:46 INFO 140042773481280] #quality_metric: host=algo-1, epoch=136, train rmse <loss>=0.239683368158\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 573.5270977020264, \"sum\": 573.5270977020264, \"min\": 573.5270977020264}}, \"EndTime\": 1550845846.194367, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845845.620421}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:46 INFO 140042773481280] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 47403, \"sum\": 47403.0, \"min\": 47403}, \"Total Records Seen\": {\"count\": 1, \"max\": 4734820, \"sum\": 4734820.0, \"min\": 4734820}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 138, \"sum\": 138.0, \"min\": 138}}, \"EndTime\": 1550845846.194579, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 136}, \"StartTime\": 1550845845.620809}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:46 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60221.5535404 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:46.194] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 137, \"duration\": 572, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:46 INFO 140042773481280] #quality_metric: host=algo-1, epoch=137, batch=0 train rmse <loss>=0.270464436603\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:46 INFO 140042773481280] #quality_metric: host=algo-1, epoch=137, train rmse <loss>=0.244077773502\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 566.356897354126, \"sum\": 566.356897354126, \"min\": 566.356897354126}}, \"EndTime\": 1550845846.761198, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845846.194437}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:46 INFO 140042773481280] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 47749, \"sum\": 47749.0, \"min\": 47749}, \"Total Records Seen\": {\"count\": 1, \"max\": 4769380, \"sum\": 4769380.0, \"min\": 4769380}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 139, \"sum\": 139.0, \"min\": 139}}, \"EndTime\": 1550845846.761408, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 137}, \"StartTime\": 1550845846.194812}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:46 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60983.469729 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:46.761] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 138, \"duration\": 565, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:46 INFO 140042773481280] #quality_metric: host=algo-1, epoch=138, batch=0 train rmse <loss>=0.290997797273\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:47 INFO 140042773481280] #quality_metric: host=algo-1, epoch=138, train rmse <loss>=0.248750473855\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.0928440093994, \"sum\": 571.0928440093994, \"min\": 571.0928440093994}}, \"EndTime\": 1550845847.33278, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845846.761263}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:47 INFO 140042773481280] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 48095, \"sum\": 48095.0, \"min\": 48095}, \"Total Records Seen\": {\"count\": 1, \"max\": 4803940, \"sum\": 4803940.0, \"min\": 4803940}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 140, \"sum\": 140.0, \"min\": 140}}, \"EndTime\": 1550845847.333032, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 138}, \"StartTime\": 1550845846.761653}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:47 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60472.8631622 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:47.333] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 139, \"duration\": 569, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:47 INFO 140042773481280] #quality_metric: host=algo-1, epoch=139, batch=0 train rmse <loss>=0.307133626007\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:47 INFO 140042773481280] #quality_metric: host=algo-1, epoch=139, train rmse <loss>=0.253546472482\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 606.7280769348145, \"sum\": 606.7280769348145, \"min\": 606.7280769348145}}, \"EndTime\": 1550845847.94008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845847.332867}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:47 INFO 140042773481280] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 48441, \"sum\": 48441.0, \"min\": 48441}, \"Total Records Seen\": {\"count\": 1, \"max\": 4838500, \"sum\": 4838500.0, \"min\": 4838500}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 141, \"sum\": 141.0, \"min\": 141}}, \"EndTime\": 1550845847.940321, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 139}, \"StartTime\": 1550845847.33332}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:47 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56924.4030867 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:47.940] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 140, \"duration\": 605, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:47 INFO 140042773481280] #quality_metric: host=algo-1, epoch=140, batch=0 train rmse <loss>=0.316875751803\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:48 INFO 140042773481280] #quality_metric: host=algo-1, epoch=140, train rmse <loss>=0.258301285805\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 581.5939903259277, \"sum\": 581.5939903259277, \"min\": 581.5939903259277}}, \"EndTime\": 1550845848.522216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845847.940148}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:48 INFO 140042773481280] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 48787, \"sum\": 48787.0, \"min\": 48787}, \"Total Records Seen\": {\"count\": 1, \"max\": 4873060, \"sum\": 4873060.0, \"min\": 4873060}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 142, \"sum\": 142.0, \"min\": 142}}, \"EndTime\": 1550845848.522452, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 140}, \"StartTime\": 1550845847.940587}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:48 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59382.4632503 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:48.522] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 141, \"duration\": 580, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:48 INFO 140042773481280] #quality_metric: host=algo-1, epoch=141, batch=0 train rmse <loss>=0.318614482121\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:49 INFO 140042773481280] #quality_metric: host=algo-1, epoch=141, train rmse <loss>=0.262848693299\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.6271209716797, \"sum\": 591.6271209716797, \"min\": 591.6271209716797}}, \"EndTime\": 1550845849.11437, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845848.52231}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:49 INFO 140042773481280] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 49133, \"sum\": 49133.0, \"min\": 49133}, \"Total Records Seen\": {\"count\": 1, \"max\": 4907620, \"sum\": 4907620.0, \"min\": 4907620}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 143, \"sum\": 143.0, \"min\": 143}}, \"EndTime\": 1550845849.114602, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 141}, \"StartTime\": 1550845848.52271}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:49 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58377.5782643 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:49.114] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 142, \"duration\": 590, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:49 INFO 140042773481280] #quality_metric: host=algo-1, epoch=142, batch=0 train rmse <loss>=0.311456938435\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:49 INFO 140042773481280] #quality_metric: host=algo-1, epoch=142, train rmse <loss>=0.267028371232\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 630.7878494262695, \"sum\": 630.7878494262695, \"min\": 630.7878494262695}}, \"EndTime\": 1550845849.745683, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845849.114443}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:49 INFO 140042773481280] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 49479, \"sum\": 49479.0, \"min\": 49479}, \"Total Records Seen\": {\"count\": 1, \"max\": 4942180, \"sum\": 4942180.0, \"min\": 4942180}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 144, \"sum\": 144.0, \"min\": 144}}, \"EndTime\": 1550845849.745927, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 142}, \"StartTime\": 1550845849.114861}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:49 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=54752.3281624 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:49.746] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 143, \"duration\": 629, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:49 INFO 140042773481280] #quality_metric: host=algo-1, epoch=143, batch=0 train rmse <loss>=0.295432333878\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:50 INFO 140042773481280] #quality_metric: host=algo-1, epoch=143, train rmse <loss>=0.270695041241\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 590.2738571166992, \"sum\": 590.2738571166992, \"min\": 590.2738571166992}}, \"EndTime\": 1550845850.33654, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845849.745757}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:50 INFO 140042773481280] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 49825, \"sum\": 49825.0, \"min\": 49825}, \"Total Records Seen\": {\"count\": 1, \"max\": 4976740, \"sum\": 4976740.0, \"min\": 4976740}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 145, \"sum\": 145.0, \"min\": 145}}, \"EndTime\": 1550845850.336736, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 143}, \"StartTime\": 1550845849.746233}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:50 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58513.9739246 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:50.336] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 144, \"duration\": 589, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:50 INFO 140042773481280] #quality_metric: host=algo-1, epoch=144, batch=0 train rmse <loss>=0.271522091228\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/22/2019 14:30:50 INFO 140042773481280] #quality_metric: host=algo-1, epoch=144, train rmse <loss>=0.273728688349\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 584.4399929046631, \"sum\": 584.4399929046631, \"min\": 584.4399929046631}}, \"EndTime\": 1550845850.921501, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845850.336605}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:50 INFO 140042773481280] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 50171, \"sum\": 50171.0, \"min\": 50171}, \"Total Records Seen\": {\"count\": 1, \"max\": 5011300, \"sum\": 5011300.0, \"min\": 5011300}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 146, \"sum\": 146.0, \"min\": 146}}, \"EndTime\": 1550845850.9217, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 144}, \"StartTime\": 1550845850.337027}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:50 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59096.5243916 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:50.921] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 145, \"duration\": 583, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:50 INFO 140042773481280] #quality_metric: host=algo-1, epoch=145, batch=0 train rmse <loss>=0.24154706385\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:51 INFO 140042773481280] #quality_metric: host=algo-1, epoch=145, train rmse <loss>=0.276046495397\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 584.4969749450684, \"sum\": 584.4969749450684, \"min\": 584.4969749450684}}, \"EndTime\": 1550845851.506517, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845850.921566}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:51 INFO 140042773481280] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 50517, \"sum\": 50517.0, \"min\": 50517}, \"Total Records Seen\": {\"count\": 1, \"max\": 5045860, \"sum\": 5045860.0, \"min\": 5045860}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 147, \"sum\": 147.0, \"min\": 147}}, \"EndTime\": 1550845851.506723, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 145}, \"StartTime\": 1550845850.921987}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:51 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59091.2725921 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:51.506] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 146, \"duration\": 583, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:51 INFO 140042773481280] #quality_metric: host=algo-1, epoch=146, batch=0 train rmse <loss>=0.20800267746\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:52 INFO 140042773481280] #quality_metric: host=algo-1, epoch=146, train rmse <loss>=0.277610133159\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 605.0128936767578, \"sum\": 605.0128936767578, \"min\": 605.0128936767578}}, \"EndTime\": 1550845852.112019, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845851.506585}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:52 INFO 140042773481280] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 50863, \"sum\": 50863.0, \"min\": 50863}, \"Total Records Seen\": {\"count\": 1, \"max\": 5080420, \"sum\": 5080420.0, \"min\": 5080420}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 148, \"sum\": 148.0, \"min\": 148}}, \"EndTime\": 1550845852.112189, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 146}, \"StartTime\": 1550845851.506981}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:52 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57095.0975742 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:52.112] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 147, \"duration\": 603, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:52 INFO 140042773481280] #quality_metric: host=algo-1, epoch=147, batch=0 train rmse <loss>=0.173973533591\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:52 INFO 140042773481280] #quality_metric: host=algo-1, epoch=147, train rmse <loss>=0.278426730393\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 581.4790725708008, \"sum\": 581.4790725708008, \"min\": 581.4790725708008}}, \"EndTime\": 1550845852.693945, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845852.112075}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:52 INFO 140042773481280] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 51209, \"sum\": 51209.0, \"min\": 51209}, \"Total Records Seen\": {\"count\": 1, \"max\": 5114980, \"sum\": 5114980.0, \"min\": 5114980}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 149, \"sum\": 149.0, \"min\": 149}}, \"EndTime\": 1550845852.694149, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 147}, \"StartTime\": 1550845852.112435}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:52 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59399.2047223 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:52.694] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 148, \"duration\": 580, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:52 INFO 140042773481280] #quality_metric: host=algo-1, epoch=148, batch=0 train rmse <loss>=0.143259438755\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:53 INFO 140042773481280] #quality_metric: host=algo-1, epoch=148, train rmse <loss>=0.278542578086\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 581.6080570220947, \"sum\": 581.6080570220947, \"min\": 581.6080570220947}}, \"EndTime\": 1550845853.276043, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845852.694011}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:53 INFO 140042773481280] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 51555, \"sum\": 51555.0, \"min\": 51555}, \"Total Records Seen\": {\"count\": 1, \"max\": 5149540, \"sum\": 5149540.0, \"min\": 5149540}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 150, \"sum\": 150.0, \"min\": 150}}, \"EndTime\": 1550845853.276263, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 148}, \"StartTime\": 1550845852.694401}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:53 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59383.5822985 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:53.276] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 149, \"duration\": 580, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:53 INFO 140042773481280] #quality_metric: host=algo-1, epoch=149, batch=0 train rmse <loss>=0.120596162383\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:53 INFO 140042773481280] #quality_metric: host=algo-1, epoch=149, train rmse <loss>=0.278033023485\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.5929737091064, \"sum\": 572.5929737091064, \"min\": 572.5929737091064}}, \"EndTime\": 1550845853.849131, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845853.276118}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:53 INFO 140042773481280] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 51901, \"sum\": 51901.0, \"min\": 51901}, \"Total Records Seen\": {\"count\": 1, \"max\": 5184100, \"sum\": 5184100.0, \"min\": 5184100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 151, \"sum\": 151.0, \"min\": 151}}, \"EndTime\": 1550845853.849505, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 149}, \"StartTime\": 1550845853.276506}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:53 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60302.3481263 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:53.849] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 150, \"duration\": 571, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:53 INFO 140042773481280] #quality_metric: host=algo-1, epoch=150, batch=0 train rmse <loss>=0.110791585895\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:54 INFO 140042773481280] #quality_metric: host=algo-1, epoch=150, train rmse <loss>=0.276990957286\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 605.2830219268799, \"sum\": 605.2830219268799, \"min\": 605.2830219268799}}, \"EndTime\": 1550845854.455116, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845853.849197}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:54 INFO 140042773481280] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 52247, \"sum\": 52247.0, \"min\": 52247}, \"Total Records Seen\": {\"count\": 1, \"max\": 5218660, \"sum\": 5218660.0, \"min\": 5218660}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 152, \"sum\": 152.0, \"min\": 152}}, \"EndTime\": 1550845854.4555, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 150}, \"StartTime\": 1550845853.849801}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:54 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57033.0737748 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:54.455] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 151, \"duration\": 604, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:54 INFO 140042773481280] #quality_metric: host=algo-1, epoch=151, batch=0 train rmse <loss>=0.115245526308\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:55 INFO 140042773481280] #quality_metric: host=algo-1, epoch=151, train rmse <loss>=0.275516107418\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 592.7689075469971, \"sum\": 592.7689075469971, \"min\": 592.7689075469971}}, \"EndTime\": 1550845855.048849, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845854.45518}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:55 INFO 140042773481280] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 52593, \"sum\": 52593.0, \"min\": 52593}, \"Total Records Seen\": {\"count\": 1, \"max\": 5253220, \"sum\": 5253220.0, \"min\": 5253220}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 153, \"sum\": 153.0, \"min\": 153}}, \"EndTime\": 1550845855.049086, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 151}, \"StartTime\": 1550845854.456049}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:55 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58255.6737444 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:55.049] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 152, \"duration\": 591, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:55 INFO 140042773481280] #quality_metric: host=algo-1, epoch=152, batch=0 train rmse <loss>=0.130104259351\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:55 INFO 140042773481280] #quality_metric: host=algo-1, epoch=152, train rmse <loss>=0.273707304715\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.5149078369141, \"sum\": 580.5149078369141, \"min\": 580.5149078369141}}, \"EndTime\": 1550845855.629873, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845855.048914}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:55 INFO 140042773481280] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 52939, \"sum\": 52939.0, \"min\": 52939}, \"Total Records Seen\": {\"count\": 1, \"max\": 5287780, \"sum\": 5287780.0, \"min\": 5287780}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 154, \"sum\": 154.0, \"min\": 154}}, \"EndTime\": 1550845855.630095, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 152}, \"StartTime\": 1550845855.049328}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:55 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59494.9190968 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:55.630] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 153, \"duration\": 579, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:55 INFO 140042773481280] #quality_metric: host=algo-1, epoch=153, batch=0 train rmse <loss>=0.15006797363\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:56 INFO 140042773481280] #quality_metric: host=algo-1, epoch=153, train rmse <loss>=0.271658068536\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 608.4871292114258, \"sum\": 608.4871292114258, \"min\": 608.4871292114258}}, \"EndTime\": 1550845856.238912, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845855.629941}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:56 INFO 140042773481280] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 53285, \"sum\": 53285.0, \"min\": 53285}, \"Total Records Seen\": {\"count\": 1, \"max\": 5322340, \"sum\": 5322340.0, \"min\": 5322340}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 155, \"sum\": 155.0, \"min\": 155}}, \"EndTime\": 1550845856.23911, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 153}, \"StartTime\": 1550845855.630393}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:56 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56765.8168113 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:56.239] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 154, \"duration\": 607, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:56 INFO 140042773481280] #quality_metric: host=algo-1, epoch=154, batch=0 train rmse <loss>=0.171505742925\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:56 INFO 140042773481280] #quality_metric: host=algo-1, epoch=154, train rmse <loss>=0.269453825234\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.1549987792969, \"sum\": 572.1549987792969, \"min\": 572.1549987792969}}, \"EndTime\": 1550845856.811513, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845856.238978}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:56 INFO 140042773481280] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 53631, \"sum\": 53631.0, \"min\": 53631}, \"Total Records Seen\": {\"count\": 1, \"max\": 5356900, \"sum\": 5356900.0, \"min\": 5356900}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 156, \"sum\": 156.0, \"min\": 156}}, \"EndTime\": 1550845856.811708, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 154}, \"StartTime\": 1550845856.239327}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:56 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60366.9137923 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:56.811] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 155, \"duration\": 570, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:56 INFO 140042773481280] #quality_metric: host=algo-1, epoch=155, batch=0 train rmse <loss>=0.192505289971\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:57 INFO 140042773481280] #quality_metric: host=algo-1, epoch=155, train rmse <loss>=0.267171585918\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.5259780883789, \"sum\": 572.5259780883789, \"min\": 572.5259780883789}}, \"EndTime\": 1550845857.38452, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845856.811577}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:57 INFO 140042773481280] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 53977, \"sum\": 53977.0, \"min\": 53977}, \"Total Records Seen\": {\"count\": 1, \"max\": 5391460, \"sum\": 5391460.0, \"min\": 5391460}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 157, \"sum\": 157.0, \"min\": 157}}, \"EndTime\": 1550845857.384696, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 155}, \"StartTime\": 1550845856.811962}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:57 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60330.3573245 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:57.384] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 156, \"duration\": 571, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:57 INFO 140042773481280] #quality_metric: host=algo-1, epoch=156, batch=0 train rmse <loss>=0.212176694075\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:57 INFO 140042773481280] #quality_metric: host=algo-1, epoch=156, train rmse <loss>=0.264879698404\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.5780067443848, \"sum\": 591.5780067443848, \"min\": 591.5780067443848}}, \"EndTime\": 1550845857.976567, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845857.384573}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:57 INFO 140042773481280] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 54323, \"sum\": 54323.0, \"min\": 54323}, \"Total Records Seen\": {\"count\": 1, \"max\": 5426020, \"sum\": 5426020.0, \"min\": 5426020}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 158, \"sum\": 158.0, \"min\": 158}}, \"EndTime\": 1550845857.976761, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 156}, \"StartTime\": 1550845857.384956}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:57 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58385.4788003 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:57.976] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 157, \"duration\": 590, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:57 INFO 140042773481280] #quality_metric: host=algo-1, epoch=157, batch=0 train rmse <loss>=0.230168167914\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:58 INFO 140042773481280] #quality_metric: host=algo-1, epoch=157, train rmse <loss>=0.262639363028\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 610.1009845733643, \"sum\": 610.1009845733643, \"min\": 610.1009845733643}}, \"EndTime\": 1550845858.587176, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845857.97663}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:58 INFO 140042773481280] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 54669, \"sum\": 54669.0, \"min\": 54669}, \"Total Records Seen\": {\"count\": 1, \"max\": 5460580, \"sum\": 5460580.0, \"min\": 5460580}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 159, \"sum\": 159.0, \"min\": 159}}, \"EndTime\": 1550845858.587394, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 157}, \"StartTime\": 1550845857.977043}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:58 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56611.7374246 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:58.587] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 158, \"duration\": 608, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:58 INFO 140042773481280] #quality_metric: host=algo-1, epoch=158, batch=0 train rmse <loss>=0.246406613037\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:59 INFO 140042773481280] #quality_metric: host=algo-1, epoch=158, train rmse <loss>=0.260505588797\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 586.9309902191162, \"sum\": 586.9309902191162, \"min\": 586.9309902191162}}, \"EndTime\": 1550845859.174633, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845858.587244}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:59 INFO 140042773481280] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 55015, \"sum\": 55015.0, \"min\": 55015}, \"Total Records Seen\": {\"count\": 1, \"max\": 5495140, \"sum\": 5495140.0, \"min\": 5495140}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 160, \"sum\": 160.0, \"min\": 160}}, \"EndTime\": 1550845859.174824, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 158}, \"StartTime\": 1550845858.58767}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:59 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58847.9710817 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:59.175] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 159, \"duration\": 585, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:59 INFO 140042773481280] #quality_metric: host=algo-1, epoch=159, batch=0 train rmse <loss>=0.260958258437\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:59 INFO 140042773481280] #quality_metric: host=algo-1, epoch=159, train rmse <loss>=0.258528274107\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 589.6499156951904, \"sum\": 589.6499156951904, \"min\": 589.6499156951904}}, \"EndTime\": 1550845859.764754, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845859.174696}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:59 INFO 140042773481280] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 55361, \"sum\": 55361.0, \"min\": 55361}, \"Total Records Seen\": {\"count\": 1, \"max\": 5529700, \"sum\": 5529700.0, \"min\": 5529700}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 161, \"sum\": 161.0, \"min\": 161}}, \"EndTime\": 1550845859.764966, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 159}, \"StartTime\": 1550845859.175072}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:59 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=58575.3802375 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:30:59.765] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 160, \"duration\": 588, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:30:59 INFO 140042773481280] #quality_metric: host=algo-1, epoch=160, batch=0 train rmse <loss>=0.273954389034\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:00 INFO 140042773481280] #quality_metric: host=algo-1, epoch=160, train rmse <loss>=0.256753367525\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 621.1137771606445, \"sum\": 621.1137771606445, \"min\": 621.1137771606445}}, \"EndTime\": 1550845860.386349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845859.764819}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:00 INFO 140042773481280] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 55707, \"sum\": 55707.0, \"min\": 55707}, \"Total Records Seen\": {\"count\": 1, \"max\": 5564260, \"sum\": 5564260.0, \"min\": 5564260}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 162, \"sum\": 162.0, \"min\": 162}}, \"EndTime\": 1550845860.386555, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 160}, \"StartTime\": 1550845859.765204}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:00 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=55610.7280738 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:00.386] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 161, \"duration\": 619, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:00 INFO 140042773481280] #quality_metric: host=algo-1, epoch=161, batch=0 train rmse <loss>=0.285552101766\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/22/2019 14:31:00 INFO 140042773481280] #quality_metric: host=algo-1, epoch=161, train rmse <loss>=0.25522409174\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 581.9649696350098, \"sum\": 581.9649696350098, \"min\": 581.9649696350098}}, \"EndTime\": 1550845860.968799, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845860.386416}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:00 INFO 140042773481280] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 56053, \"sum\": 56053.0, \"min\": 56053}, \"Total Records Seen\": {\"count\": 1, \"max\": 5598820, \"sum\": 5598820.0, \"min\": 5598820}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 163, \"sum\": 163.0, \"min\": 163}}, \"EndTime\": 1550845860.969143, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 161}, \"StartTime\": 1550845860.3868}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:00 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59333.7282935 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:00.969] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 162, \"duration\": 580, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:00 INFO 140042773481280] #quality_metric: host=algo-1, epoch=162, batch=0 train rmse <loss>=0.29590610809\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:01 INFO 140042773481280] #quality_metric: host=algo-1, epoch=162, train rmse <loss>=0.253981413792\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 584.9571228027344, \"sum\": 584.9571228027344, \"min\": 584.9571228027344}}, \"EndTime\": 1550845861.554385, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845860.96887}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:01 INFO 140042773481280] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 56399, \"sum\": 56399.0, \"min\": 56399}, \"Total Records Seen\": {\"count\": 1, \"max\": 5633380, \"sum\": 5633380.0, \"min\": 5633380}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 164, \"sum\": 164.0, \"min\": 164}}, \"EndTime\": 1550845861.55459, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 162}, \"StartTime\": 1550845860.969398}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:01 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59046.3332246 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:01.554] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 163, \"duration\": 583, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:01 INFO 140042773481280] #quality_metric: host=algo-1, epoch=163, batch=0 train rmse <loss>=0.30515540557\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:02 INFO 140042773481280] #quality_metric: host=algo-1, epoch=163, train rmse <loss>=0.253064426106\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.6870460510254, \"sum\": 580.6870460510254, \"min\": 580.6870460510254}}, \"EndTime\": 1550845862.135692, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845861.554449}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:02 INFO 140042773481280] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 56745, \"sum\": 56745.0, \"min\": 56745}, \"Total Records Seen\": {\"count\": 1, \"max\": 5667940, \"sum\": 5667940.0, \"min\": 5667940}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 165, \"sum\": 165.0, \"min\": 165}}, \"EndTime\": 1550845862.135948, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 163}, \"StartTime\": 1550845861.554822}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:02 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59458.5571711 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:02.136] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 164, \"duration\": 579, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:02 INFO 140042773481280] #quality_metric: host=algo-1, epoch=164, batch=0 train rmse <loss>=0.313410006199\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:02 INFO 140042773481280] #quality_metric: host=algo-1, epoch=164, train rmse <loss>=0.252510870271\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 600.9340286254883, \"sum\": 600.9340286254883, \"min\": 600.9340286254883}}, \"EndTime\": 1550845862.737188, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845862.135778}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:02 INFO 140042773481280] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 57091, \"sum\": 57091.0, \"min\": 57091}, \"Total Records Seen\": {\"count\": 1, \"max\": 5702500, \"sum\": 5702500.0, \"min\": 5702500}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 166, \"sum\": 166.0, \"min\": 166}}, \"EndTime\": 1550845862.737392, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 164}, \"StartTime\": 1550845862.136222}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:02 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57476.9966312 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:02.737] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 165, \"duration\": 599, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:02 INFO 140042773481280] #quality_metric: host=algo-1, epoch=165, batch=0 train rmse <loss>=0.320743148481\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:03 INFO 140042773481280] #quality_metric: host=algo-1, epoch=165, train rmse <loss>=0.252356590691\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 573.0438232421875, \"sum\": 573.0438232421875, \"min\": 573.0438232421875}}, \"EndTime\": 1550845863.310699, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845862.737252}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:03 INFO 140042773481280] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 57437, \"sum\": 57437.0, \"min\": 57437}, \"Total Records Seen\": {\"count\": 1, \"max\": 5737060, \"sum\": 5737060.0, \"min\": 5737060}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 167, \"sum\": 167.0, \"min\": 167}}, \"EndTime\": 1550845863.310914, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 165}, \"StartTime\": 1550845862.737624}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:03 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60270.7059592 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:03.311] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 166, \"duration\": 571, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:03 INFO 140042773481280] #quality_metric: host=algo-1, epoch=166, batch=0 train rmse <loss>=0.327183446121\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:03 INFO 140042773481280] #quality_metric: host=algo-1, epoch=166, train rmse <loss>=0.252634742093\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 574.8891830444336, \"sum\": 574.8891830444336, \"min\": 574.8891830444336}}, \"EndTime\": 1550845863.88612, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845863.310766}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:03 INFO 140042773481280] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 57783, \"sum\": 57783.0, \"min\": 57783}, \"Total Records Seen\": {\"count\": 1, \"max\": 5771620, \"sum\": 5771620.0, \"min\": 5771620}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 168, \"sum\": 168.0, \"min\": 168}}, \"EndTime\": 1550845863.886487, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 166}, \"StartTime\": 1550845863.311199}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:03 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60062.2297358 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:03.886] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 167, \"duration\": 574, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:03 INFO 140042773481280] #quality_metric: host=algo-1, epoch=167, batch=0 train rmse <loss>=0.332704481765\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:04 INFO 140042773481280] #quality_metric: host=algo-1, epoch=167, train rmse <loss>=0.253373923017\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 615.5898571014404, \"sum\": 615.5898571014404, \"min\": 615.5898571014404}}, \"EndTime\": 1550845864.502361, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845863.886194}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:04 INFO 140042773481280] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 58129, \"sum\": 58129.0, \"min\": 58129}, \"Total Records Seen\": {\"count\": 1, \"max\": 5806180, \"sum\": 5806180.0, \"min\": 5806180}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 169, \"sum\": 169.0, \"min\": 169}}, \"EndTime\": 1550845864.502567, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 167}, \"StartTime\": 1550845863.88674}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:04 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56109.3744578 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:04.502] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 168, \"duration\": 614, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:04 INFO 140042773481280] #quality_metric: host=algo-1, epoch=168, batch=0 train rmse <loss>=0.337219361788\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:05 INFO 140042773481280] #quality_metric: host=algo-1, epoch=168, train rmse <loss>=0.254596085266\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 597.2061157226562, \"sum\": 597.2061157226562, \"min\": 597.2061157226562}}, \"EndTime\": 1550845865.100036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845864.502428}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:05 INFO 140042773481280] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 58475, \"sum\": 58475.0, \"min\": 58475}, \"Total Records Seen\": {\"count\": 1, \"max\": 5840740, \"sum\": 5840740.0, \"min\": 5840740}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 170, \"sum\": 170.0, \"min\": 170}}, \"EndTime\": 1550845865.100237, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 168}, \"StartTime\": 1550845864.502801}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:05 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57835.9648488 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:05.100] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 169, \"duration\": 595, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:05 INFO 140042773481280] #quality_metric: host=algo-1, epoch=169, batch=0 train rmse <loss>=0.340569181856\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:05 INFO 140042773481280] #quality_metric: host=algo-1, epoch=169, train rmse <loss>=0.256311934933\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.6539058685303, \"sum\": 580.6539058685303, \"min\": 580.6539058685303}}, \"EndTime\": 1550845865.68116, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845865.100099}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:05 INFO 140042773481280] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 58821, \"sum\": 58821.0, \"min\": 58821}, \"Total Records Seen\": {\"count\": 1, \"max\": 5875300, \"sum\": 5875300.0, \"min\": 5875300}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 171, \"sum\": 171.0, \"min\": 171}}, \"EndTime\": 1550845865.68137, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 169}, \"StartTime\": 1550845865.100476}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:05 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59482.8341959 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:05.681] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 170, \"duration\": 579, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:05 INFO 140042773481280] #quality_metric: host=algo-1, epoch=170, batch=0 train rmse <loss>=0.34251849048\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:06 INFO 140042773481280] #quality_metric: host=algo-1, epoch=170, train rmse <loss>=0.258516716537\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 581.9261074066162, \"sum\": 581.9261074066162, \"min\": 581.9261074066162}}, \"EndTime\": 1550845866.263573, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845865.681224}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:06 INFO 140042773481280] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 59167, \"sum\": 59167.0, \"min\": 59167}, \"Total Records Seen\": {\"count\": 1, \"max\": 5909860, \"sum\": 5909860.0, \"min\": 5909860}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 172, \"sum\": 172.0, \"min\": 172}}, \"EndTime\": 1550845866.263775, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 170}, \"StartTime\": 1550845865.681616}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:06 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59354.0146744 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:06.263] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 171, \"duration\": 580, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:06 INFO 140042773481280] #quality_metric: host=algo-1, epoch=171, batch=0 train rmse <loss>=0.342758774838\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:06 INFO 140042773481280] #quality_metric: host=algo-1, epoch=171, train rmse <loss>=0.261183937389\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 612.2620105743408, \"sum\": 612.2620105743408, \"min\": 612.2620105743408}}, \"EndTime\": 1550845866.876299, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845866.263638}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:06 INFO 140042773481280] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 59513, \"sum\": 59513.0, \"min\": 59513}, \"Total Records Seen\": {\"count\": 1, \"max\": 5944420, \"sum\": 5944420.0, \"min\": 5944420}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 173, \"sum\": 173.0, \"min\": 173}}, \"EndTime\": 1550845866.87649, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 171}, \"StartTime\": 1550845866.264005}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:06 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56414.3488723 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:06.876] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 172, \"duration\": 611, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:06 INFO 140042773481280] #quality_metric: host=algo-1, epoch=172, batch=0 train rmse <loss>=0.340916639996\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:07 INFO 140042773481280] #quality_metric: host=algo-1, epoch=172, train rmse <loss>=0.264258571812\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.7560520172119, \"sum\": 572.7560520172119, \"min\": 572.7560520172119}}, \"EndTime\": 1550845867.449595, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845866.876361}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:07 INFO 140042773481280] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 59859, \"sum\": 59859.0, \"min\": 59859}, \"Total Records Seen\": {\"count\": 1, \"max\": 5978980, \"sum\": 5978980.0, \"min\": 5978980}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 174, \"sum\": 174.0, \"min\": 174}}, \"EndTime\": 1550845867.449797, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 172}, \"StartTime\": 1550845866.87681}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:07 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60302.9752877 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:07.449] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 173, \"duration\": 571, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:07 INFO 140042773481280] #quality_metric: host=algo-1, epoch=173, batch=0 train rmse <loss>=0.336586301736\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:08 INFO 140042773481280] #quality_metric: host=algo-1, epoch=173, train rmse <loss>=0.267651427402\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 576.2479305267334, \"sum\": 576.2479305267334, \"min\": 576.2479305267334}}, \"EndTime\": 1550845868.026318, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845867.44966}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:08 INFO 140042773481280] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 60205, \"sum\": 60205.0, \"min\": 60205}, \"Total Records Seen\": {\"count\": 1, \"max\": 6013540, \"sum\": 6013540.0, \"min\": 6013540}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 175, \"sum\": 175.0, \"min\": 175}}, \"EndTime\": 1550845868.026787, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 173}, \"StartTime\": 1550845867.45004}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:08 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59907.4355486 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:08.027] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 174, \"duration\": 575, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:08 INFO 140042773481280] #quality_metric: host=algo-1, epoch=174, batch=0 train rmse <loss>=0.329383587083\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:08 INFO 140042773481280] #quality_metric: host=algo-1, epoch=174, train rmse <loss>=0.271236570702\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 600.52490234375, \"sum\": 600.52490234375, \"min\": 600.52490234375}}, \"EndTime\": 1550845868.627622, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845868.026383}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:08 INFO 140042773481280] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 60551, \"sum\": 60551.0, \"min\": 60551}, \"Total Records Seen\": {\"count\": 1, \"max\": 6048100, \"sum\": 6048100.0, \"min\": 6048100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 176, \"sum\": 176.0, \"min\": 176}}, \"EndTime\": 1550845868.627843, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 174}, \"StartTime\": 1550845868.027064}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:08 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57513.9182074 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:08.628] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 175, \"duration\": 599, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:08 INFO 140042773481280] #quality_metric: host=algo-1, epoch=175, batch=0 train rmse <loss>=0.319015990332\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:09 INFO 140042773481280] #quality_metric: host=algo-1, epoch=175, train rmse <loss>=0.274854668639\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 584.5739841461182, \"sum\": 584.5739841461182, \"min\": 584.5739841461182}}, \"EndTime\": 1550845869.212703, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845868.627697}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:09 INFO 140042773481280] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 60897, \"sum\": 60897.0, \"min\": 60897}, \"Total Records Seen\": {\"count\": 1, \"max\": 6082660, \"sum\": 6082660.0, \"min\": 6082660}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 177, \"sum\": 177.0, \"min\": 177}}, \"EndTime\": 1550845869.21294, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 175}, \"StartTime\": 1550845868.628099}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:09 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59080.5550726 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:09.213] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 176, \"duration\": 583, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:09 INFO 140042773481280] #quality_metric: host=algo-1, epoch=176, batch=0 train rmse <loss>=0.305372514712\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:09 INFO 140042773481280] #quality_metric: host=algo-1, epoch=176, train rmse <loss>=0.278323065063\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 595.6220626831055, \"sum\": 595.6220626831055, \"min\": 595.6220626831055}}, \"EndTime\": 1550845869.80887, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845869.212781}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:09 INFO 140042773481280] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 61243, \"sum\": 61243.0, \"min\": 61243}, \"Total Records Seen\": {\"count\": 1, \"max\": 6117220, \"sum\": 6117220.0, \"min\": 6117220}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 178, \"sum\": 178.0, \"min\": 178}}, \"EndTime\": 1550845869.809057, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 176}, \"StartTime\": 1550845869.213216}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:09 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57989.2955601 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:09.809] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 177, \"duration\": 594, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:09 INFO 140042773481280] #quality_metric: host=algo-1, epoch=177, batch=0 train rmse <loss>=0.288596409495\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:10 INFO 140042773481280] #quality_metric: host=algo-1, epoch=177, train rmse <loss>=0.281454317152\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.0809860229492, \"sum\": 580.0809860229492, \"min\": 580.0809860229492}}, \"EndTime\": 1550845870.38946, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845869.808931}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:10 INFO 140042773481280] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 61589, \"sum\": 61589.0, \"min\": 61589}, \"Total Records Seen\": {\"count\": 1, \"max\": 6151780, \"sum\": 6151780.0, \"min\": 6151780}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 179, \"sum\": 179.0, \"min\": 179}}, \"EndTime\": 1550845870.389695, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 177}, \"StartTime\": 1550845869.809346}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:10 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59537.6584356 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:10.389] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 178, \"duration\": 578, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:10 INFO 140042773481280] #quality_metric: host=algo-1, epoch=178, batch=0 train rmse <loss>=0.269119638364\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/22/2019 14:31:11 INFO 140042773481280] #quality_metric: host=algo-1, epoch=178, train rmse <loss>=0.284077982209\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 611.6819381713867, \"sum\": 611.6819381713867, \"min\": 611.6819381713867}}, \"EndTime\": 1550845871.001684, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845870.389535}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:11 INFO 140042773481280] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 61935, \"sum\": 61935.0, \"min\": 61935}, \"Total Records Seen\": {\"count\": 1, \"max\": 6186340, \"sum\": 6186340.0, \"min\": 6186340}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 180, \"sum\": 180.0, \"min\": 180}}, \"EndTime\": 1550845871.001881, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 178}, \"StartTime\": 1550845870.389969}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:11 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56467.0696053 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:11.002] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 179, \"duration\": 610, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:11 INFO 140042773481280] #quality_metric: host=algo-1, epoch=179, batch=0 train rmse <loss>=0.247642165304\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:11 INFO 140042773481280] #quality_metric: host=algo-1, epoch=179, train rmse <loss>=0.286062428708\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 570.5640316009521, \"sum\": 570.5640316009521, \"min\": 570.5640316009521}}, \"EndTime\": 1550845871.572756, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845871.00175}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:11 INFO 140042773481280] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 62281, \"sum\": 62281.0, \"min\": 62281}, \"Total Records Seen\": {\"count\": 1, \"max\": 6220900, \"sum\": 6220900.0, \"min\": 6220900}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 181, \"sum\": 181.0, \"min\": 181}}, \"EndTime\": 1550845871.572932, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 179}, \"StartTime\": 1550845871.002165}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:11 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60539.5897905 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:11.573] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 180, \"duration\": 569, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:11 INFO 140042773481280] #quality_metric: host=algo-1, epoch=180, batch=0 train rmse <loss>=0.225052287066\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:12 INFO 140042773481280] #quality_metric: host=algo-1, epoch=180, train rmse <loss>=0.287327437022\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.268009185791, \"sum\": 572.268009185791, \"min\": 572.268009185791}}, \"EndTime\": 1550845872.145473, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845871.572812}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:12 INFO 140042773481280] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 62627, \"sum\": 62627.0, \"min\": 62627}, \"Total Records Seen\": {\"count\": 1, \"max\": 6255460, \"sum\": 6255460.0, \"min\": 6255460}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 182, \"sum\": 182.0, \"min\": 182}}, \"EndTime\": 1550845872.145718, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 180}, \"StartTime\": 1550845871.573173}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:12 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60348.3662139 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:12.145] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 181, \"duration\": 571, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:12 INFO 140042773481280] #quality_metric: host=algo-1, epoch=181, batch=0 train rmse <loss>=0.202317566816\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:12 INFO 140042773481280] #quality_metric: host=algo-1, epoch=181, train rmse <loss>=0.287848087905\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 576.5509605407715, \"sum\": 576.5509605407715, \"min\": 576.5509605407715}}, \"EndTime\": 1550845872.722591, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845872.14556}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:12 INFO 140042773481280] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 62973, \"sum\": 62973.0, \"min\": 62973}, \"Total Records Seen\": {\"count\": 1, \"max\": 6290020, \"sum\": 6290020.0, \"min\": 6290020}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 183, \"sum\": 183.0, \"min\": 183}}, \"EndTime\": 1550845872.722795, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 181}, \"StartTime\": 1550845872.146009}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:12 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59906.3957013 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:12.722] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 182, \"duration\": 575, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:12 INFO 140042773481280] #quality_metric: host=algo-1, epoch=182, batch=0 train rmse <loss>=0.180381912543\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:13 INFO 140042773481280] #quality_metric: host=algo-1, epoch=182, train rmse <loss>=0.287647557655\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 605.781078338623, \"sum\": 605.781078338623, \"min\": 605.781078338623}}, \"EndTime\": 1550845873.328837, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845872.722657}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:13 INFO 140042773481280] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 63319, \"sum\": 63319.0, \"min\": 63319}, \"Total Records Seen\": {\"count\": 1, \"max\": 6324580, \"sum\": 6324580.0, \"min\": 6324580}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 184, \"sum\": 184.0, \"min\": 184}}, \"EndTime\": 1550845873.329048, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 182}, \"StartTime\": 1550845872.723026}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:13 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57017.1907866 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:13.329] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 183, \"duration\": 604, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:13 INFO 140042773481280] #quality_metric: host=algo-1, epoch=183, batch=0 train rmse <loss>=0.160086401618\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:13 INFO 140042773481280] #quality_metric: host=algo-1, epoch=183, train rmse <loss>=0.286785740352\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 575.8528709411621, \"sum\": 575.8528709411621, \"min\": 575.8528709411621}}, \"EndTime\": 1550845873.905165, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845873.328908}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:13 INFO 140042773481280] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 63665, \"sum\": 63665.0, \"min\": 63665}, \"Total Records Seen\": {\"count\": 1, \"max\": 6359140, \"sum\": 6359140.0, \"min\": 6359140}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 185, \"sum\": 185.0, \"min\": 185}}, \"EndTime\": 1550845873.905394, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 183}, \"StartTime\": 1550845873.329279}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:13 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59976.070931 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:13.905] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 184, \"duration\": 574, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:13 INFO 140042773481280] #quality_metric: host=algo-1, epoch=184, batch=0 train rmse <loss>=0.142129748008\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:14 INFO 140042773481280] #quality_metric: host=algo-1, epoch=184, train rmse <loss>=0.28534486857\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.578088760376, \"sum\": 580.578088760376, \"min\": 580.578088760376}}, \"EndTime\": 1550845874.486282, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845873.905233}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:14 INFO 140042773481280] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 64011, \"sum\": 64011.0, \"min\": 64011}, \"Total Records Seen\": {\"count\": 1, \"max\": 6393700, \"sum\": 6393700.0, \"min\": 6393700}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 186, \"sum\": 186.0, \"min\": 186}}, \"EndTime\": 1550845874.486491, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 184}, \"StartTime\": 1550845873.905652}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:14 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59487.2281372 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:14.486] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 185, \"duration\": 579, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:14 INFO 140042773481280] #quality_metric: host=algo-1, epoch=185, batch=0 train rmse <loss>=0.127045963088\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:15 INFO 140042773481280] #quality_metric: host=algo-1, epoch=185, train rmse <loss>=0.283417636512\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 627.1941661834717, \"sum\": 627.1941661834717, \"min\": 627.1941661834717}}, \"EndTime\": 1550845875.113977, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845874.486349}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:15 INFO 140042773481280] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 64357, \"sum\": 64357.0, \"min\": 64357}, \"Total Records Seen\": {\"count\": 1, \"max\": 6428260, \"sum\": 6428260.0, \"min\": 6428260}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 187, \"sum\": 187.0, \"min\": 187}}, \"EndTime\": 1550845875.114194, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 185}, \"StartTime\": 1550845874.486752}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:15 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=55067.3648988 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:15.114] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 186, \"duration\": 626, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:15 INFO 140042773481280] #quality_metric: host=algo-1, epoch=186, batch=0 train rmse <loss>=0.115178250368\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:15 INFO 140042773481280] #quality_metric: host=algo-1, epoch=186, train rmse <loss>=0.28109815077\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 582.7028751373291, \"sum\": 582.7028751373291, \"min\": 582.7028751373291}}, \"EndTime\": 1550845875.697246, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845875.114044}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:15 INFO 140042773481280] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 64703, \"sum\": 64703.0, \"min\": 64703}, \"Total Records Seen\": {\"count\": 1, \"max\": 6462820, \"sum\": 6462820.0, \"min\": 6462820}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 188, \"sum\": 188.0, \"min\": 188}}, \"EndTime\": 1550845875.697461, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 186}, \"StartTime\": 1550845875.114512}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:15 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59273.0976914 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:15.697] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 187, \"duration\": 581, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:15 INFO 140042773481280] #quality_metric: host=algo-1, epoch=187, batch=0 train rmse <loss>=0.106641418678\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:16 INFO 140042773481280] #quality_metric: host=algo-1, epoch=187, train rmse <loss>=0.278477038086\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 581.2399387359619, \"sum\": 581.2399387359619, \"min\": 581.2399387359619}}, \"EndTime\": 1550845876.278973, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845875.697319}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:16 INFO 140042773481280] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 65049, \"sum\": 65049.0, \"min\": 65049}, \"Total Records Seen\": {\"count\": 1, \"max\": 6497380, \"sum\": 6497380.0, \"min\": 6497380}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 189, \"sum\": 189.0, \"min\": 189}}, \"EndTime\": 1550845876.27916, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 187}, \"StartTime\": 1550845875.697702}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:16 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59424.1397498 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:16.279] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 188, \"duration\": 580, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:16 INFO 140042773481280] #quality_metric: host=algo-1, epoch=188, batch=0 train rmse <loss>=0.101287045707\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:16 INFO 140042773481280] #quality_metric: host=algo-1, epoch=188, train rmse <loss>=0.275637285593\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 582.5982093811035, \"sum\": 582.5982093811035, \"min\": 582.5982093811035}}, \"EndTime\": 1550845876.862068, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845876.279035}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:16 INFO 140042773481280] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 65395, \"sum\": 65395.0, \"min\": 65395}, \"Total Records Seen\": {\"count\": 1, \"max\": 6531940, \"sum\": 6531940.0, \"min\": 6531940}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 190, \"sum\": 190.0, \"min\": 190}}, \"EndTime\": 1550845876.862414, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 188}, \"StartTime\": 1550845876.279437}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:16 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59268.5172234 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:16.862] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 189, \"duration\": 581, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:16 INFO 140042773481280] #quality_metric: host=algo-1, epoch=189, batch=0 train rmse <loss>=0.0987171499926\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:17 INFO 140042773481280] #quality_metric: host=algo-1, epoch=189, train rmse <loss>=0.272654081178\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 625.4739761352539, \"sum\": 625.4739761352539, \"min\": 625.4739761352539}}, \"EndTime\": 1550845877.48821, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845876.862145}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:17 INFO 140042773481280] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 65741, \"sum\": 65741.0, \"min\": 65741}, \"Total Records Seen\": {\"count\": 1, \"max\": 6566500, \"sum\": 6566500.0, \"min\": 6566500}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 191, \"sum\": 191.0, \"min\": 191}}, \"EndTime\": 1550845877.488421, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 189}, \"StartTime\": 1550845876.862705}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:17 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=55222.3123899 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:17.488] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 190, \"duration\": 624, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:17 INFO 140042773481280] #quality_metric: host=algo-1, epoch=190, batch=0 train rmse <loss>=0.0983667725076\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:18 INFO 140042773481280] #quality_metric: host=algo-1, epoch=190, train rmse <loss>=0.269595149082\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 570.0170993804932, \"sum\": 570.0170993804932, \"min\": 570.0170993804932}}, \"EndTime\": 1550845878.058698, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845877.488279}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:18 INFO 140042773481280] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 66087, \"sum\": 66087.0, \"min\": 66087}, \"Total Records Seen\": {\"count\": 1, \"max\": 6601060, \"sum\": 6601060.0, \"min\": 6601060}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 192, \"sum\": 192.0, \"min\": 192}}, \"EndTime\": 1550845878.058892, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 190}, \"StartTime\": 1550845877.488655}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:18 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60593.0873412 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:18.059] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 191, \"duration\": 568, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:18 INFO 140042773481280] #quality_metric: host=algo-1, epoch=191, batch=0 train rmse <loss>=0.0996288774135\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:18 INFO 140042773481280] #quality_metric: host=algo-1, epoch=191, train rmse <loss>=0.266520924345\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.8629055023193, \"sum\": 578.8629055023193, \"min\": 578.8629055023193}}, \"EndTime\": 1550845878.638067, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845878.05876}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:18 INFO 140042773481280] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 66433, \"sum\": 66433.0, \"min\": 66433}, \"Total Records Seen\": {\"count\": 1, \"max\": 6635620, \"sum\": 6635620.0, \"min\": 6635620}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 193, \"sum\": 193.0, \"min\": 193}}, \"EndTime\": 1550845878.638311, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 191}, \"StartTime\": 1550845878.059172}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:18 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59661.6042495 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:18.638] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 192, \"duration\": 577, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:18 INFO 140042773481280] #quality_metric: host=algo-1, epoch=192, batch=0 train rmse <loss>=0.101955627177\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:19 INFO 140042773481280] #quality_metric: host=algo-1, epoch=192, train rmse <loss>=0.263485301532\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 596.747875213623, \"sum\": 596.747875213623, \"min\": 596.747875213623}}, \"EndTime\": 1550845879.235373, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845878.638133}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:19 INFO 140042773481280] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 66779, \"sum\": 66779.0, \"min\": 66779}, \"Total Records Seen\": {\"count\": 1, \"max\": 6670180, \"sum\": 6670180.0, \"min\": 6670180}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 194, \"sum\": 194.0, \"min\": 194}}, \"EndTime\": 1550845879.235692, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 192}, \"StartTime\": 1550845878.638593}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:19 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57867.9429126 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:19.235] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 193, \"duration\": 595, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:19 INFO 140042773481280] #quality_metric: host=algo-1, epoch=193, batch=0 train rmse <loss>=0.104914586886\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:19 INFO 140042773481280] #quality_metric: host=algo-1, epoch=193, train rmse <loss>=0.26053773373\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.929931640625, \"sum\": 571.929931640625, \"min\": 571.929931640625}}, \"EndTime\": 1550845879.80793, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845879.235451}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:19 INFO 140042773481280] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 67125, \"sum\": 67125.0, \"min\": 67125}, \"Total Records Seen\": {\"count\": 1, \"max\": 6704740, \"sum\": 6704740.0, \"min\": 6704740}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 195, \"sum\": 195.0, \"min\": 195}}, \"EndTime\": 1550845879.80815, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 193}, \"StartTime\": 1550845879.235968}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:19 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60387.7871609 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:19.808] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 194, \"duration\": 570, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:19 INFO 140042773481280] #quality_metric: host=algo-1, epoch=194, batch=0 train rmse <loss>=0.108192564521\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:20 INFO 140042773481280] #quality_metric: host=algo-1, epoch=194, train rmse <loss>=0.257723736053\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 606.741189956665, \"sum\": 606.741189956665, \"min\": 606.741189956665}}, \"EndTime\": 1550845880.415205, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845879.807993}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:20 INFO 140042773481280] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 67471, \"sum\": 67471.0, \"min\": 67471}, \"Total Records Seen\": {\"count\": 1, \"max\": 6739300, \"sum\": 6739300.0, \"min\": 6739300}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 196, \"sum\": 196.0, \"min\": 196}}, \"EndTime\": 1550845880.415424, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 194}, \"StartTime\": 1550845879.808433}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:20 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56925.1407919 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:20.415] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 195, \"duration\": 605, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:20 INFO 140042773481280] #quality_metric: host=algo-1, epoch=195, batch=0 train rmse <loss>=0.111580973146\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[02/22/2019 14:31:20 INFO 140042773481280] #quality_metric: host=algo-1, epoch=195, train rmse <loss>=0.255086008703\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 564.7931098937988, \"sum\": 564.7931098937988, \"min\": 564.7931098937988}}, \"EndTime\": 1550845880.980498, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845880.415276}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:20 INFO 140042773481280] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 67817, \"sum\": 67817.0, \"min\": 67817}, \"Total Records Seen\": {\"count\": 1, \"max\": 6773860, \"sum\": 6773860.0, \"min\": 6773860}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 197, \"sum\": 197.0, \"min\": 197}}, \"EndTime\": 1550845880.980711, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 195}, \"StartTime\": 1550845880.415673}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:20 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=61152.9876741 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:20.980] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 196, \"duration\": 563, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:20 INFO 140042773481280] #quality_metric: host=algo-1, epoch=196, batch=0 train rmse <loss>=0.114949350399\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:21 INFO 140042773481280] #quality_metric: host=algo-1, epoch=196, train rmse <loss>=0.252665493226\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 613.5039329528809, \"sum\": 613.5039329528809, \"min\": 613.5039329528809}}, \"EndTime\": 1550845881.594661, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845880.980565}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:21 INFO 140042773481280] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 68163, \"sum\": 68163.0, \"min\": 68163}, \"Total Records Seen\": {\"count\": 1, \"max\": 6808420, \"sum\": 6808420.0, \"min\": 6808420}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 198, \"sum\": 198.0, \"min\": 198}}, \"EndTime\": 1550845881.59489, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 196}, \"StartTime\": 1550845880.980963}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:21 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=56281.6109287 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:21.595] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 197, \"duration\": 612, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:21 INFO 140042773481280] #quality_metric: host=algo-1, epoch=197, batch=0 train rmse <loss>=0.118223811405\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:22 INFO 140042773481280] #quality_metric: host=algo-1, epoch=197, train rmse <loss>=0.250501977314\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 581.7029476165771, \"sum\": 581.7029476165771, \"min\": 581.7029476165771}}, \"EndTime\": 1550845882.176908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845881.594735}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:22 INFO 140042773481280] #progress_metric: host=algo-1, completed 99 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 68509, \"sum\": 68509.0, \"min\": 68509}, \"Total Records Seen\": {\"count\": 1, \"max\": 6842980, \"sum\": 6842980.0, \"min\": 6842980}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 199, \"sum\": 199.0, \"min\": 199}}, \"EndTime\": 1550845882.17708, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 197}, \"StartTime\": 1550845881.595177}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:22 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=59379.3009508 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:22.177] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 198, \"duration\": 580, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:22 INFO 140042773481280] #quality_metric: host=algo-1, epoch=198, batch=0 train rmse <loss>=0.121367640696\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:22 INFO 140042773481280] #quality_metric: host=algo-1, epoch=198, train rmse <loss>=0.248635249923\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.8888511657715, \"sum\": 572.8888511657715, \"min\": 572.8888511657715}}, \"EndTime\": 1550845882.750252, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845882.176959}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:22 INFO 140042773481280] #progress_metric: host=algo-1, completed 99 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 68855, \"sum\": 68855.0, \"min\": 68855}, \"Total Records Seen\": {\"count\": 1, \"max\": 6877540, \"sum\": 6877540.0, \"min\": 6877540}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 200, \"sum\": 200.0, \"min\": 200}}, \"EndTime\": 1550845882.750487, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 198}, \"StartTime\": 1550845882.177333}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:22 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=60285.5199863 records/second\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:22.750] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 199, \"duration\": 571, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:22 INFO 140042773481280] #quality_metric: host=algo-1, epoch=199, batch=0 train rmse <loss>=0.124367482135\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:23 INFO 140042773481280] #quality_metric: host=algo-1, epoch=199, train rmse <loss>=0.247105987415\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:23 INFO 140042773481280] #quality_metric: host=algo-1, train rmse <loss>=0.247105987415\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 603.856086730957, \"sum\": 603.856086730957, \"min\": 603.856086730957}}, \"EndTime\": 1550845883.354616, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845882.750345}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:23 INFO 140042773481280] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 69201, \"sum\": 69201.0, \"min\": 69201}, \"Total Records Seen\": {\"count\": 1, \"max\": 6912100, \"sum\": 6912100.0, \"min\": 6912100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 201, \"sum\": 201.0, \"min\": 201}}, \"EndTime\": 1550845883.354847, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 199}, \"StartTime\": 1550845882.750729}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:23 INFO 140042773481280] #throughput_metric: host=algo-1, train throughput=57195.5284667 records/second\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:23 WARNING 140042773481280] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:23 INFO 140042773481280] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 2.665996551513672, \"sum\": 2.665996551513672, \"min\": 2.665996551513672}}, \"EndTime\": 1550845883.357852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845883.354686}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:23 INFO 140042773481280] Saved checkpoint to \"/tmp/tmpGIkPIl/state-0001.params\"\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:23.383] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 119089, \"num_examples\": 1}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 346, \"sum\": 346.0, \"min\": 346}, \"Total Records Seen\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 34560, \"sum\": 34560.0, \"min\": 34560}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1550845884.68759, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845883.383619}\n",
      "\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:24 INFO 140042773481280] #test_score (algo-1) : ('rmse', 0.21730182054182562)\u001b[0m\n",
      "\u001b[31m[02/22/2019 14:31:24 INFO 140042773481280] #quality_metric: host=algo-1, test rmse <loss>=0.217301820542\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:24.688] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 1303, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:24.688] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/test\", \"duration\": 120392, \"num_epochs\": 2, \"num_examples\": 347}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 120448.81105422974, \"sum\": 120448.81105422974, \"min\": 120448.81105422974}, \"setuptime\": {\"count\": 1, \"max\": 44.296979904174805, \"sum\": 44.296979904174805, \"min\": 44.296979904174805}}, \"EndTime\": 1550845884.688132, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1550845883.357897}\n",
      "\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:24.706] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 200, \"duration\": 1954, \"num_examples\": 346}\u001b[0m\n",
      "\u001b[31m[2019-02-22 14:31:24.706] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"duration\": 119879, \"num_epochs\": 201, \"num_examples\": 69201}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-02-22 14:31:32 Uploading - Uploading generated training model\n",
      "2019-02-22 14:31:32 Completed - Training job completed\n",
      "Billable seconds: 143\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.session import s3_input\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "recommender = sagemaker.estimator.Estimator(container,\n",
    "                                            role, \n",
    "                                            train_instance_count=1, \n",
    "                                            train_instance_type='ml.c4.xlarge',\n",
    "                                            output_path=s3_output_location,\n",
    "                                            sagemaker_session=sess)\n",
    "\n",
    "recommender.set_hyperparameters(predictor_type='regressor',\n",
    "                                feature_dim=feature_dimension,\n",
    "                                epochs=200,\n",
    "                                mini_batch_size=100,\n",
    "                                num_factors=128)\n",
    "\n",
    "\n",
    "recommender.fit({'train': s3_input(s3_train_data), \\\n",
    "                  'test': s3_input(s3_test_data)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: factorization-machines-2019-02-22-14-48-53-845\n",
      "INFO:sagemaker:Creating endpoint with name factorization-machines-2019-02-22-14-25-41-535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = recommender.deploy(instance_type='ml.c5.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_request(row):\n",
    "    vect = row['features']\n",
    "    return {'data':{ 'features': {'shape':[int(vect.size)], 'keys':list(map(int,vect.indices)), 'values':list(vect.values)}}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'data': {'features': {'shape': [8934],\n",
       "    'keys': [22, 3926],\n",
       "    'values': [1.0, 1.0]}}}]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_test_df.select('features').where('user_hash_id=-1942492617').rdd.map(build_request).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 0.7248020172119141}]}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from sagemaker.predictor import json_deserializer\n",
    "from sagemaker.predictor import json_serializer\n",
    "\n",
    "predictor.content_type = 'application/json'\n",
    "predictor.deserializer = json_deserializer\n",
    "predictor.serializer = lambda x:x\n",
    "\n",
    "predictor.predict(json.dumps({'instances': [{'data': {'features': {'shape': [8934], 'keys': [22, 3926], 'values': [1, 1]}}}]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_poi(poi_position):\n",
    "    prediction = predictor.predict(json.dumps({'instances': [{'data': {'features': {'shape': [8934], 'keys': [poi_position, 3926], 'values': [1, 1]}}}]}))\n",
    "    return prediction['predictions'][0]['score']\n",
    "\n",
    "predictions = [(poi_position, predict_poi(poi_position)) for poi_position in range(0,31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.sort(key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.8622169494628906),\n",
       " (16, 0.8516387939453125),\n",
       " (3, 0.8335628509521484),\n",
       " (8, 0.8225231170654297)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casey Jr. Circus Train\n",
      "Star Tours\n",
      "The Barnstormer\n",
      "Radiator Springs Racers\n",
      "Ellen's Energy Adventure\n",
      "Test Track\n",
      "Mickey's Fun Wheel\n",
      "Frontierland Shootin' Arcade\n"
     ]
    }
   ],
   "source": [
    "user_visited_pois = set(recommendation_sample[3]['collect_list(poiName)'])\n",
    "for (poi_position, score) in predictions[:10]:\n",
    "   recommended_poi = hash_to_poi_mapping[int(model.stages[2].labels[poi_position])]\n",
    "   if recommended_poi not in user_visited_pois:\n",
    "        print(recommended_poi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(user_hash_id=-1942492617, collect_list(poiName)=['Animation Academy', 'Swiss Family Treehouse', \"It's A Small World\", 'Main Street Cinema', 'Indiana Jones Epic Stunt Spectacular!', 'Impressions de France', 'Monsters, Inc. Mike & Sulley to the Rescue!', 'Haunted Mansion', \"Roger Rabbit's Car Toon Spin\"], poi_names(max(recommendations), collect_list(poiName, 0, 0))='[(\\'Pirates of the Caribbean\\', 1.0013824701309204), (\"Ellen\\'s Energy Adventure\", 0.9788758158683777), (\\'Disney Junior - Live on Stage!\\', 0.7382391691207886), (\"Frontierland Shootin\\' Arcade\", 0.4183497130870819), (\\'Test Track\\', 0.34399351477622986), (\\'Casey Jr. Circus Train\\', 0.23990291357040405), (\\'Pirates of the Caribbean\\', 0.19927802681922913)]')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with spark recommendations\n",
    "recommendation_sample[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
